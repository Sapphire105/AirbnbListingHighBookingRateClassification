---
title: "EDA"
author: "Sahitya"
date: "29/04/2020"
output: html_document
---

```{r}
library(caret)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(lubridate)
library(tidyr)
#library(rapportools)
```

Loading the train data

```{r}
# Load train data - Replace blank cells with NA
df_x_main <- read.csv('airbnb_train_x.csv', na.strings = c("", "NA"))
df_y <- read.csv('airbnb_train_y.csv', na.strings = c("", "NA"))
df_x <- df_x_main
```

Loading the test data

```{r}
tdf_x_main <- read.csv('airbnb_test_x.csv', na.strings = c("", "NA"))
tdf <- tdf_x_main
```


Check for missingness

```{r}
# Check for missingness
colSums(is.na(df_x))
```

There are a lot of columns with missing data but it's easier to understand using proportions

```{r, fig.width=10,fig.height=10}

# missing.values <- df_x_main %>%
#   gather(key = "key", value = "val") %>%
#   mutate(isna = is.na(val)) %>%
#   group_by(key) %>%
#   mutate(total = n()) %>%
#   group_by(key, total, isna) %>%
#   summarise(num.isna = n()) %>%
#   mutate(pct = num.isna / total * 100)
# 
# 
# levels <-
#     (missing.values  %>% filter(isna == T) %>% arrange(desc(pct)))$key
# 
# percentage.plot <- missing.values %>%
#       ggplot() +
#         geom_bar(aes(x = reorder(key, desc(pct)),
#                      y = pct, fill=isna),
#                  stat = 'identity', alpha=0.8) +
#       scale_x_discrete(limits = levels) +
#       scale_fill_manual(name = "",
#                         values = c('steelblue', 'tomato3'), labels = c("Present", "Missing")) +
#       coord_flip() +
#       labs(title = "Percentage of missing values", x =
#              'Variable', y = "% of missing values")
# 
# percentage.plot

```

We can also see how the rows are -

```{r, fig.width=10,fig.height=10}
# row.plot <- df_x %>%
#   mutate(id = row_number()) %>%
#   gather(-id, key = "key", value = "val") %>%
#   mutate(isna = is.na(val)) %>%
#   ggplot(aes(key, id, fill = isna)) +
#     geom_raster(alpha=0.8) +
#     scale_fill_manual(name = "",
#         values = c('steelblue', 'tomato3'),
#         labels = c("Present", "Missing")) +
#     scale_x_discrete(limits = levels) +
#     labs(x = "Variable",
#            y = "Row Number", title = "Missing values in rows") +
#     coord_flip()
# 
# row.plot
```

In dealing with the missingness, let's first create missingness indicators for all the variables. For this, we can define a function. We shall use this once we are sure we've made a fair amount of cleaning to most of the columns.

```{r}
appendNAs <- function(dataset, cols) {
  append_these = data.frame( is.na(dataset[, cols] ))
  names(append_these) = paste(names(append_these), "NA", sep = "_")
  dataset = cbind(dataset, append_these)
  dataset[is.na(dataset)] = -1
  return(dataset)
}
```

A glimpse at the structure of the data

```{r}
glimpse(df_x)
```

Inspect the columns that have numeric data -

1	accommodates	Factor
2	availability_30	Factor
3	availability_365	int
4	availability_60	Factor
5	availability_90	Factor
6	bathrooms	Factor
7	bedrooms	Factor
8	beds	Factor
9	cleaning_fee	Factor - (needs to be cleaned - has $ symbol like $250.00)
10	extra_people	Factor - (needs to be cleaned - has $ symbol like $250.00)
11	guests_included	num
12	host_acceptance_rate	Factor - (needs to be cleaned - has format like so - 100%)
13	host_listings_count	Factor
14	host_response_rate	Factor - (needs to be cleaned - has format like so - 100%)
15	host_total_listings_count	Factor
16	latitude	Factor
17	longitude	Factor
18	maximum_nights	num
19	minimum_nights	int
20	monthly_price	Factor - (needs to be cleaned - has $ symbol like $250.00)
21	price	Factor - (needs to be cleaned - has $ symbol like $250.00)
22	security_deposit	Factor - (needs to be cleaned - has $ symbol like $250.00)
23	square_feet	int 
24	weekly_price	Factor - (needs to be cleaned - has $ symbol like $250.00)

First let's explore the columns with the $ symbols and commas and percentages -

```{r, fig.width=10,fig.height=150}

dollar_num_cols = c("cleaning_fee", "extra_people", "monthly_price", "price", "security_deposit", "weekly_price")
perc_num_cols = c("host_acceptance_rate", "host_response_rate")

# The columns which have prices
qplot(cleaning_fee, data = df_x) + coord_flip()
qplot(extra_people, data = df_x) + coord_flip()
qplot(monthly_price, data = df_x) + coord_flip()
qplot(price, data = df_x) + coord_flip()
qplot(security_deposit, data = df_x) + coord_flip()
qplot(weekly_price, data = df_x) + coord_flip()

# Observations

# cleaning_fee
# - Majority of NAs
# - Has a few f and t

# extra_people
# - has some longitude/latitude information -
# - 40.7115296729, 37.7172817854, 34.0550373047, 34.0544381605, 34.04703657, 34.0305066944, 33.9847962097, 33.7751358179, 30.3646152573

# price
# -looks fine except for a very small number of NAs

# security_deposit
# mostly NAs
# second most popular category is $0.00

# weekly_price
# - looks fine
# - mostly NAs

# monthly_price
# - NA is the most popular - there are lots
# - other values are mostly 4 digits or more with very few 3 digits

# The columns which have %
qplot(host_acceptance_rate, data = df_x) + coord_flip()
qplot(host_response_rate, data = df_x) + coord_flip()

# host_acceptance_rate
# - most popular category - NA
# - all others are within format

# host_response_rate
# - 100% is most popular
# - Next is NA
# - There are 4 out of place categories - Apartment, Loft, House, Condominium

```

Storing the discrepancies in a variable for later use -

```{r}
extra_people_discrepancies = c(40.7115296729, 37.7172817854, 34.0550373047, 34.0544381605, 34.04703657, 34.0305066944, 33.9847962097, 33.7751358179, 30.3646152573)
hostresponserate_discrepancies = c("Apartment", "Loft", "House", "Condominium")
```

```{r}
df_x[df_x$extra_people %in% extra_people_discrepancies,]
```

All the columns seem to be misplaced. We can store this separately and rearrange them -

```{r}
misplacedX <- c(16246, 30584, 47615, 56281, 65792, 72540, 75208, 92585, 96068)

misplaced_df_x <- df_x[df_x$extra_people %in% extra_people_discrepancies,]
df_x[df_x$extra_people %in% extra_people_discrepancies, 3:70] <- NA
df_x[df_x$X %in% misplacedX, ]
```

Now we can work on transforming the data -

```{r}
# First, the columns which have prices -

# cleaning_fee, extra_people, price, security_deposit, weekly_price, monthly_price

df_x$cleaning_fee <- as.numeric(str_replace_all(df_x$cleaning_fee, "[\\$,]", ""))
  # test data
tdf$cleaning_fee <- as.numeric(str_replace_all(tdf$cleaning_fee, "[\\$,]", ""))

df_x$extra_people <- as.numeric(str_replace_all(df_x$extra_people, "[\\$,]", ""))
  # test data
tdf$extra_people <- as.numeric(str_replace_all(tdf$extra_people, "[\\$,]", ""))

df_x$price <- as.numeric(str_replace_all(df_x$price, "[\\$,]", ""))
  # test data
tdf$price <- as.numeric(str_replace_all(tdf$price, "[\\$,]", ""))

df_x$security_deposit <- as.numeric(str_replace_all(df_x$security_deposit, "[\\$,]", ""))
  # test data
tdf$security_deposit <- as.numeric(str_replace_all(tdf$security_deposit, "[\\$,]", ""))

df_x$weekly_price <- as.numeric(str_replace_all(df_x$weekly_price, "[\\$,]", ""))
  # test data
tdf$weekly_price <- as.numeric(str_replace_all(tdf$weekly_price, "[\\$,]", ""))

df_x$monthly_price <- as.numeric(str_replace_all(df_x$monthly_price, "[\\$,]", ""))
  # test data
tdf$monthly_price <- as.numeric(str_replace_all(tdf$monthly_price, "[\\$,]", ""))

# Next, the columns which havedf_x$host_acceptance_rate - has %

# host_acceptance_rate, host_response_rate

df_x$host_acceptance_rate <- as.numeric(str_replace_all(df_x$host_acceptance_rate, "%", ""))
  # test data
tdf$host_acceptance_rate <- as.numeric(str_replace_all(tdf$host_acceptance_rate, "%", ""))

df_x$host_response_rate <- as.numeric(str_replace_all(df_x$host_response_rate, "%", ""))
  # test data
tdf$host_response_rate <- as.numeric(str_replace_all(tdf$host_response_rate, "%", ""))

```

The other columns now -

1	accommodates	Factor
2	availability_30	Factor
3	availability_365	int
4	availability_60	Factor
5	availability_90	Factor
6	bathrooms	Factor
7	bedrooms	Factor
8	beds	Factor
#  9	cleaning_fee	Factor - (needs to be cleaned - has $ symbol like $250.00)
#  10	extra_people	Factor - (needs to be cleaned - has $ symbol like $250.00)
11	guests_included	num
#  12	host_acceptance_rate	Factor - (needs to be cleaned - has format like so - 100%)
13	host_listings_count	Factor
#  14	host_response_rate	Factor - (needs to be cleaned - has format like so - 100%)
15	host_total_listings_count	Factor
16	latitude	Factor
17	longitude	Factor
18	maximum_nights	num
19	minimum_nights	int
#  20	monthly_price	Factor - (needs to be cleaned - has $ symbol like $250.00)
#  21	price	Factor - (needs to be cleaned - has $ symbol like $250.00)
#  22	security_deposit	Factor - (needs to be cleaned - has $ symbol like $250.00)
23	square_feet	int 
#  24	weekly_price	Factor - (needs to be cleaned - has $ symbol like $250.00)

```{r}
qplot(as.numeric(accommodates), data = df_x)
qplot(as.numeric(availability_30), data = df_x)
qplot(as.numeric(availability_365), data = df_x)
qplot(as.numeric(availability_60), data = df_x) + coord_flip()
qplot(as.numeric(availability_90), data = df_x) + coord_flip()
qplot(as.numeric(bathrooms), data = df_x) + coord_flip()
qplot(as.numeric(bedrooms), data = df_x)
qplot(as.numeric(beds), data = df_x)
qplot(as.numeric(guests_included), data = df_x) + coord_flip()
qplot(as.numeric(host_listings_count), data = df_x) + coord_flip()
qplot(as.numeric(host_total_listings_count), data = df_x) + coord_flip()
# qplot(longitude, data = df_x)
# qplot(latitude, data = df_x)
qplot(as.numeric(maximum_nights), data = df_x)
qplot(as.numeric(minimum_nights), data = df_x)
qplot(as.numeric(square_feet), data = df_x)
```

Visualize in log scale -

```{r}

qplot(as.numeric(accommodates), data = df_x) + scale_x_log10()
qplot(as.numeric(availability_30), data = df_x) + scale_x_log10()
qplot(as.numeric(availability_365), data = df_x) + scale_x_log10()
qplot(as.numeric(availability_60), data = df_x) + coord_flip() + scale_x_log10()
qplot(as.numeric(availability_90), data = df_x) + coord_flip() + scale_x_log10()
qplot(as.numeric(bathrooms), data = df_x) + coord_flip() + scale_x_log10()
qplot(as.numeric(bedrooms), data = df_x) + scale_x_log10()
qplot(as.numeric(beds), data = df_x) + scale_x_log10()
qplot(as.numeric(guests_included), data = df_x) + coord_flip() + scale_x_log10()
qplot(as.numeric(host_listings_count), data = df_x) + coord_flip() + scale_x_log10()
qplot(as.numeric(host_total_listings_count), data = df_x) + coord_flip() + scale_x_log10()
# qplot(longitude, data = df_x)
# qplot(latitude, data = df_x)
qplot(as.numeric(maximum_nights), data = df_x) + scale_x_log10()
qplot(as.numeric(minimum_nights), data = df_x) + scale_x_log10()
qplot(as.numeric(square_feet), data = df_x) + scale_x_log10()


```

Convert these columns to numeric

```{r}

num_cols <- c("accommodates", "availability_30", "availability_365", "availability_60", 
              "availability_90", "bathrooms", "bedrooms", "beds", "guests_included", 
              "host_listings_count", "host_total_listings_count", 
              "maximum_nights", "minimum_nights", "square_feet")

geo_cols <- c("latitude", "longitude")

df_x[,num_cols] <- sapply(df_x[,num_cols],as.numeric)
  # test data
tdf[,num_cols] <- sapply(tdf[,num_cols],as.numeric)

df_x[,geo_cols] <- sapply(df_x[,geo_cols],as.character)
df_x[,geo_cols] <- sapply(df_x[,geo_cols],as.numeric)
  # test data
tdf[,geo_cols] <- sapply(tdf[,geo_cols],as.character)
tdf[,geo_cols] <- sapply(tdf[,geo_cols],as.numeric)

```

Observations for these variables -


1. availability_30
- Mostly 0s
- There is f and t but negligible

2. availability_365
- Looks good
- Can be visualized in a log scale 

3. availability_60
- Unclear
- Need to look at the table
- Few values which are like so - "Santa Monica, California, United States" - Might have to find the rows where the data is shuffled like this

4. availability_90
- Unclear
- Need to look at the table
- Few values which are names I guess, like 'Amanda', 'Winni'

5. Bathrooms
- Mostly 1
- Has some names like 'Oceanview', 'North Shoal Creek', 'Long Beach'

6. Bedrooms 
- Decent - mostly 1
- has some values like - 'within an hour'

7. guests_included
- There is a negative scale in the graph - need to find out what this is about
- Otherwise, mostly 0

8. accommodates
- All good except for one t

9. host_listings_count
- Have to see in a table

10. maximum_nights
- Have to see in a table

11. minimum_nights 
- Have to see in a table

12. latitude, longitude
- Have to see in a table


```{r, fig.height=10, fig.width=30}
ggplot(gather(df_x[, num_cols]), aes(value)) + 
    geom_histogram(stat = "count") + 
    facet_wrap(~key, scales = 'free_x')
```

Now a look at categorical variables -

# 1	bed_type	Factor
# 2	cancellation_policy	Factor
# 3	city	Factor
# 4	city_name	Factor
# 5	country	Factor
# 6	country_code	Factor
# 7	experiences_offered	Factor
8	host_has_profile_pic	Factor
9	host_identity_verified	Factor
10	host_is_superhost	Factor
# 11	host_location	Factor
# 12	host_neighbourhood	Factor
# 13	host_response_time	Factor
14	instant_bookable	Factor
15	is_business_travel_ready	Factor
16	is_location_exact	Factor
# 17	jurisdiction_names	Factor
# 18	license	Factor
# 19	market	Factor
# 20	neighbourhood	Factor
# 21	property_type	Factor
22	require_guest_phone_verification	Factor
23	require_guest_profile_picture	Factor
24	requires_license	Factor
# 25	room_type	Factor
# 26	smart_location	Factor
# 27	state	Factor

There are a bunch of columns which have 't' and 'f'

1. df$host_has_profile_pic - factor
2. df$host_identity_verified - factor
3. df$host_is_superhost - factor
4. df$instant_bookable - factor
5. df$is_business_travel_ready - factor
6. df$is_location_exact - factor
7. df$require_guest_phone_verification - factor
8. df$require_guest_profile_picture - factor
9. df$requires_license - factor

First, histograms.

```{r echo=FALSE}
qplot(x = host_has_profile_pic, data = df_x) 
qplot(x = host_identity_verified, data = df_x)
qplot(x = host_is_superhost, data = df_x) + coord_flip()
qplot(x = instant_bookable, data = df_x)
qplot(x = is_business_travel_ready, data = df_x) 
qplot(x = is_location_exact, data = df_x)
qplot(x = require_guest_phone_verification, data = df_x)
qplot(x = require_guest_profile_picture, data = df_x)
qplot(x = requires_license, data = df_x)
```

These columns seem to comprise mostly of 'f's and 't's.

We need to figure out how to deal with this specific column since more than 45% of the values are missing. We'll get to that but first, let's take care of the other columns. 

```{r}
# View(table(tdf$host_has_profile_pic))
# View(table(tdf$host_identity_verified))
# View(table(tdf$host_is_superhost))
# View(table(tdf$instant_bookable))
# View(table(tdf$is_business_travel_ready))
# View(table(tdf$is_location_exact))
# View(table(tdf$require_guest_phone_verification))
# View(table(tdf$require_guest_profile_picture))
# View(table(tdf$requires_license))
```

Let's fix the discrepancies in the test data

```{r}
superhost_discrepancies <- c("Bed,Bath&Bike in Sunny Santa Monica", "Pristine Mid-Century Modern w 180Â° Canyon View!")

misplacedy <- c(775, 10274)

misplaced_tdf <- tdf[tdf$host_is_superhost %in% superhost_discrepancies, ]

tdf[tdf$host_is_superhost %in% superhost_discrepancies, 3:70] <- NA

tdf[tdf$X %in% misplacedy, ]
```

Convert t's and f's to 1s and 0s

```{r}
# 1. df$host_has_profile_pic - factor
df_x$host_has_profile_pic <- ifelse(df_x_main$host_has_profile_pic == "t", 1, 0)
qplot(x = host_has_profile_pic, data = df_x)
  # test data
tdf$host_has_profile_pic <- ifelse(tdf_x_main$host_has_profile_pic == "t", 1, 0)

# 2. df$host_identity_verified - factor
df_x$host_identity_verified <- ifelse(df_x_main$host_identity_verified == "t", 1, 0)
qplot(x = host_identity_verified, data = df_x)
  # test data
tdf$host_identity_verified <- ifelse(tdf_x_main$host_identity_verified == "t", 1, 0)

# 3. df$host_is_superhost - factor
df_x$host_is_superhost <- ifelse(df_x_main$host_is_superhost== "t", 1, 0)
qplot(x = host_is_superhost, data = df_x)
  # test data
tdf$host_is_superhost <- ifelse(tdf_x_main$host_is_superhost== "t", 1, 0)

# 4. df$instant_bookable - factor
df_x$instant_bookable <- ifelse(df_x_main$instant_bookable == "t", 1, 0)
qplot(x = instant_bookable, data = df_x)
  # test data
tdf$instant_bookable <- ifelse(tdf_x_main$instant_bookable == "t", 1, 0)  

# 5. df$is_business_travel_ready - factor
df_x$is_business_travel_ready <- ifelse(is.na(df_x_main$is_business_travel_ready), df_x_main$is_business_travel_ready, ifelse(df_x_main$is_business_travel_ready == "t", 1, 0))
qplot(x = is_business_travel_ready, data = df_x)
  # test data
tdf$is_business_travel_ready <- ifelse(is.na(tdf_x_main$is_business_travel_ready), tdf_x_main$is_business_travel_ready, ifelse(tdf_x_main$is_business_travel_ready == "t", 1, 0))

# 6. df$is_location_exact - factor
df_x$is_location_exact <- ifelse(df_x_main$is_location_exact == "t", 1, 0)
qplot(x = is_location_exact, data = df_x)
  # test data
tdf$is_location_exact <- ifelse(tdf_x_main$is_location_exact == "t", 1, 0)

# 7. df$require_guest_phone_verification - factor
df_x$require_guest_phone_verification <- ifelse(df_x_main$require_guest_phone_verification == "t", 1, 0)
qplot(x = require_guest_phone_verification, data = df_x)
  # test data
tdf$require_guest_phone_verification <- ifelse(tdf_x_main$require_guest_phone_verification == "t", 1, 0)

# 8. df$require_guest_profile_picture - factor
df_x$require_guest_profile_picture <- ifelse(df_x_main$require_guest_profile_picture == "t", 1, 0)
qplot(x = require_guest_profile_picture, data = df_x)
  # test data
tdf$require_guest_profile_picture <- ifelse(tdf_x_main$require_guest_profile_picture == "t", 1, 0)

# 9. df$requires_license - factor
df_x$requires_license <- ifelse(df_x_main$requires_license == "t", 1, 0)
qplot(x = requires_license, data = df_x)
  # test data
tdf$requires_license <- ifelse(tdf_x_main$requires_license == "t", 1, 0)

```

Moving on to other categorical variables -

1	bed_type	Factor
2	cancellation_policy	Factor
3	city	Factor
4	city_name	Factor
5	country	Factor
6	country_code	Factor
7	experiences_offered	Factor
# 8	host_has_profile_pic	Factor
# 9	host_identity_verified	Factor
# 10	host_is_superhost	Factor
11	host_location	Factor
12	host_neighbourhood	Factor
13	host_response_time	Factor
# 14	instant_bookable	Factor
# 15	is_business_travel_ready	Factor
# 16	is_location_exact	Factor
17	jurisdiction_names	Factor
18	license	Factor
19	market	Factor
20	neighbourhood	Factor
21	property_type	Factor
# 22	require_guest_phone_verification	Factor
# 23	require_guest_profile_picture	Factor
# 24	requires_license	Factor
25	room_type	Factor
26	smart_location	Factor
27	state	Factor

```{r, fig.height=15, fig.width=10}
qplot(df_x$bed_type) + coord_flip()
qplot(df_x$cancellation_policy) + coord_flip()
qplot(df_x$city) + coord_flip() # unclear - need to look at the table
qplot(df_x$city_name) + coord_flip()
qplot(df_x$country)+ coord_flip()
qplot(df_x$country_code)+ coord_flip()
qplot(df_x$experiences_offered)+ coord_flip()
qplot(df_x$host_location)+ coord_flip() # Unclear - need to look at the table
qplot(df_x$host_neighbourhood)+ coord_flip() # Unclear - need to look at the table
qplot(df_x$host_response_time)+ coord_flip()
qplot(df_x$jurisdiction_names)+ coord_flip() # Categorical list
qplot(df_x$license)+ coord_flip() # Unclear - need to look at the table
qplot(df_x$market)+ coord_flip() # Looks clean for the most part
qplot(df_x$neighbourhood)+ coord_flip() # Unclear - need to look at the table
qplot(df_x$property_type)+ coord_flip() # Looks neat for the most part
qplot(df_x$room_type)+ coord_flip() # clean
qplot(df_x$smart_location)+ coord_flip() # Unclear - need to look at the table
qplot(df_x$state)+ coord_flip() # needs to be cleaned
```

Table views for the variables with unclear plots -

```{r}
# View(table(df_x$city)) # 738 categories
# View(table(df_x$host_location)) # 2154 categories; Format like so - Liverpool, England, United Kingdom
# View(table(df_x$host_neighbourhood)) # 1303 categories
# View(table(df_x$license)) # Looks like some unique ID - 7474 many categories
# View(table(df_x$neighbourhood)) # 1093 categories; Examples - Woodside, Windsor
# View(table(df_x$smart_location)) # 750 categories - Can be cleaned by converting all to upper case
```

First, let's clean the state column -

```{r}
library(rapportools) # for trim.space

# View with all values in upper case

View(table(str_to_upper(df_x$state)))

# The data discrepancies are -

# 1. BAJA CALIFORNIA
# 2. NEW YORK
# 3. SECC TERRAZAS
# 4. MP

# Let's change that 

df_x$state <- trim.space(str_to_upper(df_x$state))

df_x$state[df_x$state == 'NEW YORK'] <- 'NY'
df_x$state[df_x$state == 'BAJA CALIFORNIA'] <- 'CA'
df_x$state[df_x$state == 'SECC TERRAZAS'] <- 'CA'
df_x$state[df_x$state == 'MP'] <- 'NY'

# There are only 17 samples for MD which can be changed to DC
# There are only 2 samples for NJ which can be changed to NY

df_x$state[df_x$state == 'MD'] <- 'DC'
df_x$state[df_x$state == 'NJ'] <- 'NY'

# There is a separate column for LA which can be changed to CA

df_x$state[df_x$state == 'LA'] <- 'CA'
unique(df_x$state)
  # test data

tdf$state <- trim.space(str_to_upper(tdf$state))
View(table(tdf$state))

tdf$state[tdf$state == 'LA'] <- 'CA'
tdf$state[tdf$state == 'MD'] <- 'DC'

unique(tdf$state)
```

```{r}
# View(sort(table(tdf$city), decreasing = T)) 
# View(table(tdf$host_location)) 
# View(table(tdf$host_neighbourhood)) 
# View(table(tdf$license)) 
# View(table(tdf$neighbourhood)) 
# View(table(tdf$smart_location)) 
```

They are pretty much okay.

Let's capitalize and trim these categorical columns -

```{r}

# city
df_x$city <- trim.space(str_to_upper(df_x$city))
  # test data
tdf$city <- trim.space(str_to_upper(tdf$city))

# city_name
df_x$city_name <- trim.space(str_to_upper(df_x$city_name))
  # test data
tdf$city_name <- trim.space(str_to_upper(tdf$city_name))

# host_location
df_x$host_location <- trim.space(str_to_upper(df_x$host_location))
  # test data
tdf$host_location <- trim.space(str_to_upper(tdf$host_location))

# host_neighborhood
df_x$host_neighbourhood <- trim.space(str_to_upper(df_x$host_neighbourhood))
  # test data
tdf$host_neighbourhood <- trim.space(str_to_upper(tdf$host_neighbourhood))

# neighborhood
df_x$neighbourhood <- trim.space(str_to_upper(df_x$neighbourhood))
  # test data
tdf$neighbourhood <- trim.space(str_to_upper(tdf$neighbourhood))

# smart_location
df_x$smart_location <- trim.space(str_to_upper(df_x$smart_location))
  # test data
tdf$smart_location <- trim.space(str_to_upper(tdf$smart_location)) 

```

Now let's view the number of categories for each of these variables and see if they have reduced -

```{r}
length(unique(df_x_main$city)) # 739
length(unique(df_x$city)) # 526
length(unique(df_x_main$host_location)) # 2155
length(unique(df_x$host_location)) # 2118
length(unique(df_x_main$host_neighbourhood)) # 1304
length(unique(df_x$host_neighbourhood)) # 1295
length(unique(df_x_main$neighborhood)) # 62392
length(unique(df_x$neighborhood)) # 62392
length(unique(df_x_main$smart_location)) # 751
length(unique(df_x$smart_location)) # 634
```

The test data -

```{r}
length(unique(tdf_x_main$city)) # 265
length(unique(tdf$city)) # 221
length(unique(tdf_x_main$host_location)) # 600
length(unique(tdf$host_location)) # 593
length(unique(tdf_x_main$host_neighbourhood)) # 879
length(unique(tdf$host_neighbourhood)) # 877
length(unique(tdf_x_main$neighborhood)) # 8194
length(unique(tdf$neighborhood)) # 8194
length(unique(tdf_x_main$smart_location)) # 268
length(unique(tdf$smart_location)) # 250
```

Now, the date columns; Let's convert them to date type; And then extract the number of years of experience the listing's host has had as a host; We shall also find the number of years since becoming a host did it take for them to get their first review - 

```{r}
df_x <- df_x %>%
  mutate(first_review = ymd(first_review),
         host_since = ymd(host_since),
         host_age = 2020 - year(host_since),
         start_to_review_gap = year(first_review) - year(host_since))

  # test data
tdf <- tdf %>%
  mutate(first_review = ymd(first_review),
         host_since = ymd(host_since),
         host_age = 2020 - year(host_since),
         start_to_review_gap = year(first_review) - year(host_since))
```

View the distribution of the host_age and start_to_review_gap -

```{r}
qplot(df_x$host_since, df_x$first_review)
qplot(df_x$host_age)
qplot(df_x$start_to_review_gap)
```

Replace the NAs in start_to_review_gap and host_age with the respective means of the column

```{r}
library(tidyr)

sTor_gap <- mean(df_x$start_to_review_gap)
df_x$start_to_review_gap <- replace_na(df_x$start_to_review_gap, sTor_gap)
  # test data
tdf$start_to_review_gap <- replace_na(tdf$start_to_review_gap, sTor_gap)

host_age_mean <- mean(df_x$host_age)
df_x$host_age <- replace_na(df_x$host_age, host_age_mean)
  # test data
tdf$host_age <- replace_na(tdf$start_to_review_gap, host_age_mean)

```

There are some start_to_review_gaps which are lesser than zero (where the first_review date is earlier than the host_since date)

Let's clean it up

```{r}
df_x$start_to_review_gap[df_x$start_to_review_gap < 0] <- sTor_gap
  # test data
tdf$start_to_review_gap[tdf$start_to_review_gap < 0] <- sTor_gap
```

Let's bucket these variables based on the quantiles -

```{r}
# host_age / experience

df_x <- df_x %>% 
  mutate(host_age_q = ntile(host_age, 5))


# df_x %>% 
#   mutate(host_age_q = ntile(host_age, 5)) %>%
#   group_by(host_age_q, host_age) %>%
#   summarize(n = n()) %>%
#   group_by(host_age_q) %>%
#   summarize(total = sum(n),
#             min_age = min(host_age),
#             max_age = max(host_age))

# 1	20000	2	4	
# 2	20000	4	5	
# 3	20000	5	6	
# 4	20000	6	8	
# 5	20000	8	12	


df_x <- df_x %>%	
	mutate( 
  		host_lowExp = ifelse(host_age_q == 1, 1, 0),
  		host_lowMedExp = ifelse(host_age_q == 2, 1, 0),
  		host_medExp = ifelse(host_age_q == 3, 1, 0),
  		host_medHighExp = ifelse(host_age_q == 4, 1, 0),
  		host_highExp = ifelse(host_age_q == 5, 1, 0)
  		)

tdf <- tdf %>%
  mutate(
      host_lowExp = ifelse((host_age >= 2) & (host_age < 4), 1, 0),
  		host_lowMedExp = ifelse((host_age >= 4) & (host_age < 5), 1, 0),
  		host_medExp = ifelse((host_age >= 5) & (host_age < 6), 1, 0),
  		host_medHighExp = ifelse((host_age >= 6) & (host_age < 8), 1, 0),
  		host_highExp = ifelse((host_age >= 8) & (host_age < 12), 1, 0) 
  )
```

Now the start_to_review_gap - 

Let's first check the outliers to impute -
```{r}
sTorR_OutVals <- boxplot(df_x$start_to_review_gap)$out
sTorR_OutVals
sTorR_TestOutVals <- boxplot(tdf$start_to_review_gap)$out
sTorR_TestOutVals
```

Change the outliers - 

```{r}
df_x$start_to_review_gap[df_x$start_to_review_gap > 7] <- 6
tdf$start_to_review_gap[tdf$start_to_review_gap > 7] <- 6
```


```{r}
df_x <- df_x %>% 
  mutate(sTor_gap_q = ntile(start_to_review_gap, 3))


# df_x %>%
#   mutate(sTor_gap_q = ntile(start_to_review_gap, 3)) %>%
#   group_by(sTor_gap_q, start_to_review_gap) %>%
#   summarize(n = n()) %>%
#   group_by(sTor_gap_q) %>%
#   summarize(total = sum(n),
#             min_age = min(start_to_review_gap),
#             max_age = max(start_to_review_gap))

# 1	33334	0	1	
# 2	33333	1	2	
# 3	33333	2	7	

df_x <- df_x %>%
	mutate(
  		NoGap_sTor = ifelse(sTor_gap_q == 1, 1, 0),
  		Yr1Gap_sTor = ifelse(sTor_gap_q == 2, 1, 0),
  		HighGap_sTor = ifelse(sTor_gap_q == 3, 1, 0)
  		)

tdf <- tdf %>%
  mutate(
      NoGap_sTor = ifelse(start_to_review_gap == 0, 1, 0),
  		Yr1Gap_sTor = ifelse(start_to_review_gap == 1, 1, 0),
  		HighGap_sTor = ifelse(start_to_review_gap >= 2, 1, 0)
  )

```

Dummy variables for state -

```{r}
df_x <- df_x %>%
	mutate(
  		In_CA = ifelse(state == 'CA', 1, 0),
  		In_CO = ifelse(state == 'CO', 1, 0),
  		In_DC = ifelse(state == 'DC', 1, 0),
  		In_IL = ifelse(state == 'IL', 1, 0),
  		In_MA = ifelse(state == 'MA', 1, 0),
  		In_NC = ifelse(state == 'NC', 1, 0),
  		In_NY = ifelse(state == 'NY', 1, 0),
  		In_OR = ifelse(state == 'OR', 1, 0),
  		In_TN = ifelse(state == 'TN', 1, 0),
  		In_TX = ifelse(state == 'TX', 1, 0),
  		In_WA = ifelse(state == 'WA', 1, 0)
  		)
  # test data

tdf <- tdf %>%
	mutate(
  		In_CA = ifelse(state == 'CA', 1, 0),
  		In_CO = ifelse(state == 'CO', 1, 0),
  		In_DC = ifelse(state == 'DC', 1, 0),
  		In_IL = ifelse(state == 'IL', 1, 0),
  		In_MA = ifelse(state == 'MA', 1, 0),
  		In_NC = ifelse(state == 'NC', 1, 0),
  		In_NY = ifelse(state == 'NY', 1, 0),
  		In_OR = ifelse(state == 'OR', 1, 0),
  		In_TN = ifelse(state == 'TN', 1, 0),
  		In_TX = ifelse(state == 'TX', 1, 0),
  		In_WA = ifelse(state == 'WA', 1, 0)
  		)

```

Let's also include city_name dummies. There might be more variance with these because parameters might change based on cities rather than state on the whole - 

```{r}
unique(df_x$city_name)
unique(tdf$city_name)
```

Let's create dummies then,

```{r}

df_x <- df_x %>%
	mutate(
  		In_NAS = ifelse(city_name == 'NASHVILLE', 1, 0),
  		In_LA = ifelse(city_name == 'LOS ANGELES', 1, 0),
  		In_SD = ifelse(city_name == 'SAN DIEGO', 1, 0),
  		In_WDC = ifelse(city_name == 'WASHINGTON DC', 1, 0),
  		In_NWO = ifelse(city_name == 'NEW ORLEANS', 1, 0),
  		In_SFO = ifelse(city_name == 'SAN FRANCISCO', 1, 0),
  		In_NYC = ifelse(city_name == 'NEW YORK', 1, 0),
  		In_SEA = ifelse(city_name == 'SEATTLE', 1, 0),
  		In_CHI = ifelse(city_name == 'CHICAGO', 1, 0),
  		In_BOS = ifelse(city_name == 'BOSTON', 1, 0),
  		In_AUS = ifelse(city_name == 'AUSTIN', 1, 0),
  		In_PO = ifelse(city_name == 'PORTLAND', 1, 0),
  		In_DEN = ifelse(city_name == 'DENVER', 1, 0),
  		In_SCU = ifelse(city_name == 'SANTA CRUZ', 1, 0),
  		In_OAK = ifelse(city_name == 'OAKLAND', 1, 0),
  		In_ASH = ifelse(city_name == 'ASHEVILLE', 1, 0)
  		)
  # test data

tdf <- tdf %>%
	mutate(
  		In_NAS = ifelse(city_name == 'NASHVILLE', 1, 0),
  		In_LA = ifelse(city_name == 'LOS ANGELES', 1, 0),
  		In_SD = ifelse(city_name == 'SAN DIEGO', 1, 0),
  		In_WDC = ifelse(city_name == 'WASHINGTON DC', 1, 0),
  		In_NWO = ifelse(city_name == 'NEW ORLEANS', 1, 0),
  		In_SFO = ifelse(city_name == 'SAN FRANCISCO', 1, 0),
  		In_NYC = ifelse(city_name == 'NEW YORK', 1, 0),
  		In_SEA = ifelse(city_name == 'SEATTLE', 1, 0),
  		In_CHI = ifelse(city_name == 'CHICAGO', 1, 0),
  		In_BOS = ifelse(city_name == 'BOSTON', 1, 0),
  		In_AUS = ifelse(city_name == 'AUSTIN', 1, 0),
  		In_PO = ifelse(city_name == 'PORTLAND', 1, 0),
  		In_DEN = ifelse(city_name == 'DENVER', 1, 0),
  		In_SCU = ifelse(city_name == 'SANTA CRUZ', 1, 0),
  		In_OAK = ifelse(city_name == 'OAKLAND', 1, 0),
  		In_ASH = ifelse(city_name == 'ASHEVILLE', 1, 0)
  		)

```

Cancellation Policy -

```{r}
# View(table(df_x$cancellation_policy))

# 7	strict	47372
# 5	moderate	30411
# 4	flexible	21837
# 8	super_strict_30	261
# 9	super_strict_60	106
# 6	no_refunds	4

strict <- c("no_refunds", "super_strict_60", "super_strict_30", "strict")


df_x <- df_x %>%
	mutate(
  		CancelPol_Strict = ifelse(cancellation_policy %in% strict, 1, 0),
  		CancelPol_Mod = ifelse(cancellation_policy == 'moderate', 1, 0),
  		CancelPol_Flexy = ifelse(cancellation_policy == 'flexible', 1, 0)
  		)
  # test data
tdf <- tdf %>%
	mutate(
  		CancelPol_Strict = ifelse(cancellation_policy %in% strict, 1, 0),
  		CancelPol_Mod = ifelse(cancellation_policy == 'moderate', 1, 0),
  		CancelPol_Flexy = ifelse(cancellation_policy == 'flexible', 1, 0)
  		)

```

Room Type and Property Type -

```{r}
# View(table(df_x$room_type))

# 1	Entire home/apt	60892
# 2	Private room	36617
# 3	Shared room	2472

# View(table(tdf$room_type))

# 1	Entire home/apt	7425
# 2	Private room	4480
# 3	Shared room	300

df_x <- df_x %>%
	mutate(
  		WholePlace = ifelse(room_type == 'Entire home/apt', 1, 0),
  		PrivateRoom = ifelse(room_type == 'Private room', 1, 0),
  		SharedRoom = ifelse(room_type == 'Shared room', 1, 0)
  		)
  # test data
tdf <- tdf %>%
	mutate(
  		WholePlace = ifelse(room_type == 'Entire home/apt', 1, 0),
  		PrivateRoom = ifelse(room_type == 'Private room', 1, 0),
  		SharedRoom = ifelse(room_type == 'Shared room', 1, 0)
  		)

```


Property type - 

```{r}
df_x$property_type <- trim.space(str_to_upper(df_x$property_type))
tdf$property_type <- trim.space(str_to_upper(tdf$property_type))

# View(table(df_x$property_type))

apartment_types = c("APARTMENT", "CONDOMINIUM", "LOFT", "IN-LAW")
house_types = c("HOUSE", "TOWNHOUSE", "GUESTHOUSE", "TINY HOUSE", "BUNGALOW", "VILLA", "CASA PARTICULAR (CUBA)")
hotel_types = c("BED & BREAKFAST", "BED AND BREAKFAST", "SERVICED APARTMENT", "HOTEL", "APARTHOTEL", "GUEST SUITE")
holiday_types = c("RESORT", "VACATION HOME", "CABIN", "CHALET", "TIMESHARE", "BOAT", "TREEHOUSE", "YURT", "COTTAGE", "HUT", "ISLAND", "BOUTIQUE HOTEL", "CASTLE", "EARTH HOUSE", "CAVE", "TRAIN", "FARM STAY", "BARN", "LIGHTHOUSE", "NATURE LODGE", "PLANE")
other_types = c("OTHER", "DORM", "CAMPER/RV", "HOSTEL", "TENT", "TIPI")

df_x <- df_x %>%
	mutate(
  		propertyApartment = ifelse(property_type %in% apartment_types, 1, 0),
  		propertyHouse = ifelse(property_type %in% house_types, 1, 0),
  		propertyHotel = ifelse(property_type %in% hotel_types, 1, 0),
  		propertyHoliday = ifelse(property_type %in% holiday_types, 1, 0),
  		propertyOther = ifelse(property_type %in% other_types, 1, 0)
  		)
  # test data
# View(table(tdf$property_type))

tdf <- tdf %>%
	mutate(
  		propertyApartment = ifelse(property_type %in% apartment_types, 1, 0),
  		propertyHouse = ifelse(property_type %in% house_types, 1, 0),
  		propertyHotel = ifelse(property_type %in% hotel_types, 1, 0),
  		propertyHoliday = ifelse(property_type %in% holiday_types, 1, 0),
  		propertyOther = ifelse(property_type %in% other_types, 1, 0)
  		)
```

Bed Type -

```{r}
# View(table(df_x$bed_type))
# View(table(tdf$bed_type))
# View(table(df_x$bed_type, df_y$high_booking_rate))
  
# 3	  Airbed	0	449
# 4	  Couch	0	213
# 5	  Futon	0	805
# 6	  Pull-out Sofa	0	556
# 7	  Real Bed	0	72828
# 
# 10	Airbed	1	89
# 11	Couch	1	48
# 12	Futon	1	191
# 13	Pull-out Sofa	1	164
# 14	Real Bed	1	24638

uncomfyBeds = c("Airbed", "Couch", "Futon", "Pull-out Sofa")

df_x <- df_x %>%
	mutate(
  		bed_Real = ifelse(bed_type == 'Real Bed', 1, 0),
  		bed_Uncomfy = ifelse(bed_type %in% uncomfyBeds, 1, 0)
  		)
  # test data
tdf <- tdf %>%
	mutate(
  		bed_Real = ifelse(bed_type == 'Real Bed', 1, 0),
  		bed_Uncomfy = ifelse(bed_type %in% uncomfyBeds, 1, 0)
  		)
```

host_response_time

```{r}
# View(table(df_x$host_response_time, df_y$high_booking_rate))
# View(table(df_x$host_response_time))
# View(table(tdf$host_response_time))

# 1	a few days or more	0	1350
# 2	f	0	0
# 3	within a day	0	9800
# 4	within a few hours	0	14333
# 5	within an hour	0	33865
# 6	a few days or more	1	55
# 7	f	1	0
# 8	within a day	1	857
# 9	within a few hours	1	2929
# 10	within an hour	1	21008

# replacing na with the second most popular category
df_x$host_response_time <- replace_na(df_x$host_response_time, 'within a few hours')

df_x <- df_x %>%
	mutate(
  		hRes_FewDays = ifelse(host_response_time == 'a few days or more', 1, 0),
  		hRes_1Day = ifelse(host_response_time == 'within a day', 1, 0),
  		hRes_FewHours = ifelse(host_response_time == 'within a few hours', 1, 0),
  		hRes_1Hour = ifelse(host_response_time == 'within an hour', 1, 0)
  		)
  # test data
tdf <- tdf %>%
	mutate(
  		hRes_FewDays = ifelse(host_response_time == 'a few days or more', 1, 0),
  		hRes_1Day = ifelse(host_response_time == 'within a day', 1, 0),
  		hRes_FewHours = ifelse(host_response_time == 'within a few hours', 1, 0),
  		hRes_1Hour = ifelse(host_response_time == 'within an hour', 1, 0)
  		)

```


```{r}
View(df_x$host_verifications)
View(df_x$amenities)
```



Some text mining on the columns with categorical lists -

```{r}
library(qdap)

df_x$host_verifications <- as.character(df_x$host_verifications)
df_x$host_verifications <- trim.space(str_to_lower(df_x$host_verifications))
freq_verifs <- freq_terms(df_x$host_verifications, 50)

```

```{r}
plot(freq_verifs)
```

Dummies for number of host verifications

```{r}

df_x <- df_x %>%
	mutate(
  		No_of_Verifs = str_count(df_x$host_verifications, ",") + 1
  		)

# View(table(df_x$No_of_Verifs))

# 1	  1	  241
# 2	  2	  1978
# 3	  3	  16077
# 4	  4	  35876
# 5	  5	  23967
# 6	  6	  10773
# 7	  7	  4552
# 8	  8	  3522
# 9	  9	  1984
# 10	10	707
# 11	11	217
# 12	12	71
# 13	13	14
# 14	14	2

df_x <- df_x %>%
	mutate(
  		verifs_vLow = ifelse((No_of_Verifs >= 1) & (No_of_Verifs <= 2), 1, 0),
  		verifs_Med = ifelse((No_of_Verifs >= 3) & (No_of_Verifs <= 5), 1, 0),
  		verifs_High = ifelse((No_of_Verifs >= 6) & (No_of_Verifs <= 8), 1, 0),
  		verifs_VHigh = ifelse(No_of_Verifs >= 9, 1, 0)
  		)
  # test data
tdf <- tdf %>%
	mutate(
  		No_of_Verifs = str_count(tdf$host_verifications, ",") + 1
  		)

tdf <- tdf %>%
	mutate(
  		verifs_vLow = ifelse((No_of_Verifs >= 1) & (No_of_Verifs <= 2), 1, 0),
  		verifs_Med = ifelse((No_of_Verifs >= 3) & (No_of_Verifs <= 5), 1, 0),
  		verifs_High = ifelse((No_of_Verifs >= 6) & (No_of_Verifs <= 8), 1, 0),
  		verifs_VHigh = ifelse(No_of_Verifs >= 9, 1, 0)
  		)

```

Create further dummies based on popular verification types -

```{r}

# 1 phone 2 reviews 3 email 4 jumio 5 kba 6 facebook 7 governmentid 8 workemail 9 offlinegovernmentid 10 google

df_x <- df_x %>%
  mutate(
    facebookVer = ifelse(grepl("facebook", host_verifications), 1, 0),
    googleVer = ifelse(grepl("google", host_verifications), 1, 0),
    govtIDVer = ifelse(grepl("government_id", host_verifications), 1, 0),
    jumioVer = ifelse(grepl("jumio", host_verifications), 1, 0),
    kbaVer = ifelse(grepl("kba", host_verifications), 1, 0)
  )
  # test data

tdf <- tdf %>%
  mutate(
    facebookVer = ifelse(grepl("facebook", host_verifications), 1, 0),
    googleVer = ifelse(grepl("google", host_verifications), 1, 0),
    govtIDVer = ifelse(grepl("government_id", host_verifications), 1, 0),
    jumioVer = ifelse(grepl("jumio", host_verifications), 1, 0),
    kbaVer = ifelse(grepl("kba", host_verifications), 1, 0)
  )

```

Now, the harder one - amenities -

```{r}
df_x$amenities <- as.character(df_x$amenities)
df_x$amenities <- trim.space(str_to_lower(df_x$amenities))
df_x$amenities <- str_replace_all(df_x$amenities, " ", "_")
# View(df_x$amenities)
  # test data
tdf$amenities <- as.character(tdf$amenities)
tdf$amenities <- trim.space(str_to_lower(tdf$amenities))
tdf$amenities <- str_replace_all(tdf$amenities, " ", "_")
```

Further, let's count the number of amenities as well as the most popular amenities -

```{r}
df_x <- df_x %>%
  mutate(No_of_Amens = str_count(amenities, ",") + 1)

# df_x %>% 
#   mutate(amens_q = ntile(No_of_Amens, 5)) %>%
#   group_by(amens_q, No_of_Amens) %>%
#   summarize(n = n()) %>%
#   group_by(amens_q) %>%
#   summarize(total = sum(n),
#             min_age = min(No_of_Amens),
#             max_age = max(No_of_Amens))

# 1	19999	1	  13	
# 2	19998	13	17	
# 3	19998	17	21	
# 4	19998	21	25	
# 5	19998	25	78

amens_avg <- mean(df_x$No_of_Amens)

df_x$No_of_Amens <- replace_na(df_x$No_of_Amens, amens_avg)

df_x <- df_x %>%
  mutate(
    vlowAmens = ifelse((No_of_Amens >= 1) & (No_of_Amens < 13), 1, 0),
    lowAmens = ifelse((No_of_Amens >= 13) & (No_of_Amens < 17), 1, 0),
    medAmens = ifelse((No_of_Amens >= 17) & (No_of_Amens < 21), 1, 0),
    highAmens = ifelse((No_of_Amens >= 21) & (No_of_Amens < 25), 1, 0),
    vhighAmens = ifelse(No_of_Amens > 25, 1, 0)
         )
  # test data
tdf <- tdf %>%
  mutate(No_of_Amens = str_count(amenities, ",") + 1)

tdf <- tdf %>%
  mutate(
    vlowAmens = ifelse((No_of_Amens >= 1) & (No_of_Amens < 13), 1, 0),
    lowAmens = ifelse((No_of_Amens >= 13) & (No_of_Amens < 17), 1, 0),
    medAmens = ifelse((No_of_Amens >= 17) & (No_of_Amens < 21), 1, 0),
    highAmens = ifelse((No_of_Amens >= 21) & (No_of_Amens < 25), 1, 0),
    vhighAmens = ifelse(No_of_Amens > 25, 1, 0)
         )

```

```{r, fig.height=10, fig.width=10}
k <- gsub(",", " ", df_x$amenities)
freq_amenities <- freq_terms(k, 50)
plot(freq_amenities)
```

More dummies for specific amenities -

```{r}

kitchen_amens <- "kitchen|microwave|stove"
kitchen2_amens <- "coffee_maker|refrigerator"
heat_amens <- "heating"
ac_amens <- "air_conditioning"
tv_amens <- "tv|cable_tv"
wifi_amens <- "internet|wireless_internet|wifi"
pets_amens <- "pets_allowed|dogs"
luxury_amens <- "gym|hot_tub|pool|indoor_fireplace|breakfast"
petsLiveHere <- "pets_live_on_this_property"
workspace_amens <- "laptop_friendly_workspace"
parking_amens <- "free_parking_on_premises"
extrabedding <- "bed_linens|extra_pillows_and_blankets"
elevator_amens <- "elevator|elevator_in_building"
privacy_amens <- "private_entrance|lock_on_bedroom_door"

df_x[grep(kitchen_amens, df_x$amenities, value = F), "hasKitchen1"] <- 1
df_x[grep(kitchen2_amens, df_x$amenities, value = F), "hasKitchen2"] <- 1
df_x[grep(heat_amens, df_x$amenities, value = F), "hasHeating"] <- 1
df_x[grep(ac_amens, df_x$amenities, value = F), "hasAC"] <- 1
df_x[grep(tv_amens, df_x$amenities, value = F), "hasTV"] <- 1
df_x[grep(wifi_amens, df_x$amenities, value = F), "hasWiFi"] <- 1
df_x[grep(pets_amens, df_x$amenities, value = F), "PetsAllowed"] <- 1
df_x[grep(luxury_amens, df_x$amenities, value = F), "hasLuxuryAmens"] <- 1
df_x[grep(petsLiveHere, df_x$amenities, value = F), "petsLiveHere"] <- 1
df_x[grep(workspace_amens, df_x$amenities, value = F), "hasWorkspace"] <- 1
df_x[grep(parking_amens, df_x$amenities, value = F), "hasFreeParking"] <- 1
df_x[grep(extrabedding, df_x$amenities, value = F), "extraBedding"] <- 1
df_x[grep(elevator_amens, df_x$amenities, value = F), "hasElevator"] <- 1
df_x[grep(privacy_amens, df_x$amenities, value = F), "hasPrivacyAmens"] <- 1
  # test data
tdf[grep(kitchen_amens, tdf$amenities, value = F), "hasKitchen1"] <- 1
tdf[grep(kitchen2_amens, tdf$amenities, value = F), "hasKitchen2"] <- 1
tdf[grep(heat_amens, tdf$amenities, value = F), "hasHeating"] <- 1
tdf[grep(ac_amens, tdf$amenities, value = F), "hasAC"] <- 1
tdf[grep(tv_amens, tdf$amenities, value = F), "hasTV"] <- 1
tdf[grep(wifi_amens, tdf$amenities, value = F), "hasWiFi"] <- 1
tdf[grep(pets_amens, tdf$amenities, value = F), "PetsAllowed"] <- 1
tdf[grep(luxury_amens, tdf$amenities, value = F), "hasLuxuryAmens"] <- 1
tdf[grep(petsLiveHere, tdf$amenities, value = F), "petsLiveHere"] <- 1
tdf[grep(workspace_amens, tdf$amenities, value = F), "hasWorkspace"] <- 1
tdf[grep(parking_amens, tdf$amenities, value = F), "hasFreeParking"] <- 1
tdf[grep(extrabedding, tdf$amenities, value = F), "extraBedding"] <- 1
tdf[grep(elevator_amens, tdf$amenities, value = F), "hasElevator"] <- 1
tdf[grep(privacy_amens, tdf$amenities, value = F), "hasPrivacyAmens"] <- 1


```

Replace NAs in the newly created columns with 0s

```{r}
amenCols <- c("hasKitchen1", "hasKitchen2", "hasHeating", "hasAC", 
              "hasTV", "hasWiFi", "PetsAllowed", "hasLuxuryAmens", 
              "petsLiveHere", "hasWorkspace", "hasFreeParking", 
              "extraBedding", "hasElevator", "hasPrivacyAmens")

df_x$hasKitchen1 <- replace_na(df_x$hasKitchen1, 0)
df_x$hasKitchen2 <- replace_na(df_x$hasKitchen2, 0)
df_x$hasHeating <- replace_na(df_x$hasHeating, 0)
df_x$hasAC <- replace_na(df_x$hasAC, 0)
df_x$hasTV <- replace_na(df_x$hasTV, 0)
df_x$hasWiFi <- replace_na(df_x$hasWiFi, 0)
df_x$PetsAllowed <- replace_na(df_x$PetsAllowed, 0)
df_x$hasLuxuryAmens <- replace_na(df_x$hasLuxuryAmens, 0)
df_x$petsLiveHere <- replace_na(df_x$petsLiveHere, 0)
df_x$hasWorkspace <- replace_na(df_x$hasWorkspace, 0)
df_x$hasFreeParking <- replace_na(df_x$hasFreeParking, 0)
df_x$extraBedding <- replace_na(df_x$extraBedding, 0)
df_x$hasElevator <- replace_na(df_x$hasElevator, 0)
df_x$hasPrivacyAmens <- replace_na(df_x$hasPrivacyAmens, 0)
  # test data
tdf$hasKitchen1 <- replace_na(tdf$hasKitchen1, 0)
tdf$hasKitchen2 <- replace_na(tdf$hasKitchen2, 0)
tdf$hasHeating <- replace_na(tdf$hasHeating, 0)
tdf$hasAC <- replace_na(tdf$hasAC, 0)
tdf$hasTV <- replace_na(tdf$hasTV, 0)
tdf$hasWiFi <- replace_na(tdf$hasWiFi, 0)
tdf$PetsAllowed <- replace_na(tdf$PetsAllowed, 0)
tdf$hasLuxuryAmens <- replace_na(tdf$hasLuxuryAmens, 0)
tdf$petsLiveHere <- replace_na(tdf$petsLiveHere, 0)
tdf$hasWorkspace <- replace_na(tdf$hasWorkspace, 0)
tdf$hasFreeParking <- replace_na(tdf$hasFreeParking, 0)
tdf$extraBedding <- replace_na(tdf$extraBedding, 0)
tdf$hasElevator <- replace_na(tdf$hasElevator, 0)
tdf$hasPrivacyAmens <- replace_na(tdf$hasPrivacyAmens, 0)

```

I'd like to see if smoking is allowed or not from the house rules column -

For that, trim spaces and convert to lowercase first -

```{r}

df_x$house_rules <- as.character(df_x$house_rules)
df_x$house_rules <- trim.space(str_to_lower(df_x$house_rules))
  # test data
tdf$house_rules <- as.character(tdf$house_rules)
tdf$house_rules <- trim.space(str_to_lower(tdf$house_rules))

```


```{r}
df_x[grep("no smoking", df_x$house_rules, value = F), "NoSmoking"] <- 1
df_x$NoSmoking[is.na(df_x$NoSmoking)] <- 0
  # test data
tdf[grep("no smoking", tdf$house_rules, value = F), "NoSmoking"] <- 1
tdf$NoSmoking[is.na(tdf$NoSmoking)] <- 0

```

Is host from USA?

```{r}
df_x$host_location <- trim.space(str_to_lower(df_x$host_location))
  # test data
tdf$host_location <- trim.space(str_to_lower(tdf$host_location))

df_x <- df_x %>%
  mutate(
    isHost_in_US = ifelse(grepl("united states", host_location), 1, 0)
  )
  # test data
tdf <- tdf %>%
  mutate(
    isHost_in_US = ifelse(grepl("united states", host_location), 1, 0)
  )

```

More processing on the numerical columns now -

accommodates
availability_30
availability_365
availability_60
availability_90
bathrooms
bedrooms
beds
cleaning_fee
extra_people
guests_included

host_listings_count
host_response_rate
host_total_listings_count

maximum_nights
minimum_nights

price


```{r}

# View(table(df_x$guests_included)) There are some 0s
# View(table(df_x$accommodates)) There are no 0s

# Replacing the 0s and NAs in guests_included with 1s, the most popular category

df_x$guests_included[df_x$guests_included == 0] <- 1
df_x$guests_included <- replace_na(df_x$guests_included, 1)
 # test data
tdf$guests_included[tdf$guests_included == 0] <- 1
tdf$guests_included <- replace_na(tdf$guests_included, 1)

# The price can also include the cleaning fee

# summary(df_x$cleaning_fee) - median is 50

df_x$cleaning_fee <- replace_na(df_x$cleaning_fee, 50)
  # test data
tdf$cleaning_fee <- replace_na(tdf$cleaning_fee, 50)

# The security deposit has 40K NAs

# summary(df_x$security_deposit)

df_x$security_deposit <- replace_na(df_x$security_deposit, 200)
  # test data
tdf$security_deposit <- replace_na(tdf$security_deposit, 200)

df_x <- df_x %>%
  mutate(
    bathroomGuestRatio = bathrooms/accommodates,
    bedroomsGuestRatio = bedrooms/accommodates,
    bedsGuestsRatio = beds/accommodates,
    pricePerGuest = (price + cleaning_fee)/guests_included,
    sec_dep_perc = ifelse(price >=1 , (100*security_deposit)/price, 60)
  )
  # test data
tdf <- tdf %>%
  mutate(
    bathroomGuestRatio = bathrooms/accommodates,
    bedroomsGuestRatio = bedrooms/accommodates,
    bedsGuestsRatio = beds/accommodates,
    pricePerGuest = (price + cleaning_fee)/guests_included,
    sec_dep_perc = ifelse(price >=1 , (100*security_deposit)/price, 60)
  )
```

There are some sec_dep_perc that are greater than 100!

Let's change those -

```{r}
df_x$sec_dep_perc[df_x$sec_dep_perc > 100] <- 60
  # test data
tdf$sec_dep_perc[tdf$sec_dep_perc > 100] <- 60
```

Now, we can bin the security deposits -

```{r}
df_x <- df_x %>%
  mutate(
    secDep0 = ifelse(sec_dep_perc == 0, 1, 0),
    secDepGen = ifelse((sec_dep_perc > 0) & (sec_dep_perc <= 60), 1, 0),
    secDepHigh = ifelse(sec_dep_perc > 60, 1, 0)
  )
  # test data
tdf <- tdf %>%
  mutate(
    secDep0 = ifelse(sec_dep_perc == 0, 1, 0),
    secDepGen = ifelse((sec_dep_perc > 0) & (sec_dep_perc <= 60), 1, 0),
    secDepHigh = ifelse(sec_dep_perc > 60, 1, 0)
  )
```

The pricePerGuest can be further divided into dummies based on quantiles -

```{r}
# df_x %>% 
#   mutate(pPG_q = ntile(pricePerGuest, 5)) %>%
#   group_by(pPG_q, pricePerGuest) %>%
#   summarize(n = n()) %>%
#   group_by(pPG_q) %>%
#   summarize(total = sum(n),
#             min_age = min(pricePerGuest),
#             max_age = max(pricePerGuest))
# 
# summary(df_x$pricePerGuest)

df_x <- df_x %>%
  mutate(
    vlow_pPG = ifelse((pricePerGuest >= 0) & (pricePerGuest < 44), 1, 0),
    low_pPG = ifelse((pricePerGuest >= 44) & (pricePerGuest < 87.5), 1, 0),
    med_pPG = ifelse((pricePerGuest >= 87.5) & (pricePerGuest < 250), 1, 0),
    high_pPG = ifelse((pricePerGuest >= 250) & (pricePerGuest < 1000), 1, 0),
    vHigh_pPG = ifelse(pricePerGuest >= 1000, 1, 0)
  )
  # test data
tdf <- tdf%>%
  mutate(
    vlow_pPG = ifelse((pricePerGuest >= 0) & (pricePerGuest < 44), 1, 0),
    low_pPG = ifelse((pricePerGuest >= 44) & (pricePerGuest < 87.5), 1, 0),
    med_pPG = ifelse((pricePerGuest >= 87.5) & (pricePerGuest < 250), 1, 0),
    high_pPG = ifelse((pricePerGuest >= 250) & (pricePerGuest < 1000), 1, 0),
    vHigh_pPG = ifelse(pricePerGuest >= 1000, 1, 0)
  )
```

Making dummies of bathroomGuestRatio, bedsGuestRatio, and bedroomsGuestRation -

First, bedsGuestsRatio -

```{r}

# df_x %>%
#   mutate(bGR_q = ntile(bedsGuestsRatio, 5)) %>%
#   group_by(bGR_q, bedsGuestsRatio) %>%
#   summarize(n = n()) %>%
#   group_by(bGR_q) %>%
#   summarize(total = sum(n),
#             min_age = min(bedsGuestsRatio),
#             max_age = max(bedsGuestsRatio))
# 
# summary(df_x$bedsGuestsRatio)

df_x$bedsGuestsRatio <- replace_na(df_x$bedsGuestsRatio, 1)
  # test data
tdf$bedsGuestsRatio <- replace_na(tdf$bedsGuestsRatio, 1)

df_x <- df_x %>%
  mutate(
    beds_Comfy = ifelse((bedsGuestsRatio >= 0.7333333) & (bedsGuestsRatio < 1.3), 1, 0),
    beds_Cramped = ifelse(bedsGuestsRatio < 0.7333333, 1, 0),
    beds_Excess = ifelse(bedsGuestsRatio > 1.3, 1, 0)
  )
  # test data
tdf <- tdf %>%
  mutate(
    beds_Comfy = ifelse((bedsGuestsRatio >= 0.7333333) & (bedsGuestsRatio < 1.3), 1, 0),
    beds_Cramped = ifelse(bedsGuestsRatio < 0.7333333, 1, 0),
    beds_Excess = ifelse(bedsGuestsRatio > 1.3, 1, 0)
  )

```

Second, bathroomGuestRatio

```{r}
# df_x %>%
#   mutate(baGR_q = ntile(bathroomGuestRatio, 5)) %>%
#   group_by(baGR_q, bathroomGuestRatio) %>%
#   summarize(n = n()) %>%
#   group_by(baGR_q) %>%
#   summarize(total = sum(n),
#             min_age = min(bathroomGuestRatio),
#             max_age = max(bathroomGuestRatio))
# 
# summary(df_x$bathroomGuestRatio)

df_x$bathroomGuestRatio <- replace_na(df_x$bedsGuestsRatio, 0.7)
  # test data
tdf$bathroomGuestRatio <- replace_na(tdf$bathroomGuestRatio, 0.7)

df_x <- df_x %>%
  mutate(
    baths_Comfy = ifelse((bedsGuestsRatio >= 0.5) & (bedsGuestsRatio < 1.2), 1, 0),
    baths_Cramped = ifelse(bedsGuestsRatio < 0.5, 1, 0),
    baths_Excess = ifelse(bedsGuestsRatio > 1.2, 1, 0)
  )
  # test data
tdf <- tdf %>%
  mutate(
    baths_Comfy = ifelse((bedsGuestsRatio >= 0.5) & (bedsGuestsRatio < 1.2), 1, 0),
    baths_Cramped = ifelse(bedsGuestsRatio < 0.5, 1, 0),
    baths_Excess = ifelse(bedsGuestsRatio > 1.2, 1, 0)
  )
```

Finally, bedroomsGuestRation 

```{r}
# summary(df_x$bedroomsGuestRatio)

df_x$bedroomsGuestRatio <- replace_na(df_x$bedroomsGuestRatio, 0.5)
  # test data
tdf$bedroomsGuestRatio <- replace_na(tdf$bedroomsGuestRatio, 0.5)

df_x <- df_x %>%
  mutate(
    bedrooms_Comfy = ifelse((bedroomsGuestRatio >= 0.5) & (bedroomsGuestRatio < 1.2), 1, 0),
    bedrooms_Cramped = ifelse(bedroomsGuestRatio < 0.5, 1, 0),
    bedrooms_Excess = ifelse(bedroomsGuestRatio > 1.2, 1, 0)
  )
  # test data
tdf <- tdf %>%
  mutate(
    bedrooms_Comfy = ifelse((bedroomsGuestRatio >= 0.5) & (bedroomsGuestRatio < 1.2), 1, 0),
    bedrooms_Cramped = ifelse(bedroomsGuestRatio < 0.5, 1, 0),
    bedrooms_Excess = ifelse(bedroomsGuestRatio > 1.2, 1, 0)
  )
```

There are columns with text in them -
  
1. df$access - Something like 'I like to feel right at home'
2. df$amenities - {TV, \"Cable TV"}
3. df$description - "Vacation in this Nashville home featuring a premier location"
4. df$host_about - "I am from Virginia, USA and my wife is from Istanbul, Turkey"
5. df$host_location - "Nashville, Tennessee, United States", "Los Angeles, California, United States"
6. df$host_name - May & Eric, Jonathon, Jeremy, Gene, Holly, Nathan, Gregg, Alicia, Laura, Raymond
7. df$host_neighbourhood - , Silver Lake, East Village, Near Northeast/H Street Corridor, Bayou St. John
8. df$host_verifications - "['email', 'phone', 'google', 'reviews']", "['email', 'phone', 'reviews', 'jumio']"
9. df$house_rules - "No pets, parties, or indoor smoking. Feel free to use everything in kitchen bu"
10. df$interaction - "Don't hesitate to call or text any time throughout your stay! Where you are looking fo"
11. df$jurisdiction_names - "City of Los Angeles, CA", "SAN DIEGO, SAN DIEGO TOURISM MARKETING DISTRICT A, SAN"
12. df$license - "17STR-04969", "1075925", "17STR-14190"
13. df$name - "BRAND NEW ! NASHVILLE LOFT", "Silverlake Hills Home with View"
14. df$neighborhood_overview - "This modern loft is locate in a nice neighborhood near to the centennial park and just"
15. df$neighbourhood - "Silver Lake, Pacific Beach, Near Northeast/H Street Corridor, Bayou St. John, Lower H"
16. df$notes - "Its a fun beach town - the beach, the bay, the great restaurants, the wonderfu"
17. df$space - "Beautiful brand new loft in a central location. Near Vandy and Centennial park,only 2"
18. df$street - "Nashville, TN, United States", "Silver Lake, Los Angeles, CA 90026, United States"
19. df$summary - "Vacation in this Nashville home featuring a premier location - just 2 miles from downt"
20. df$transit - "Ubers are everywhere. We also have car2go's everywhere if you have an account"

----------------------------------------------------------------------------------------------------------------------------

Let's treat the numerical columns which we are not going to be binning -

Scale availabilities and accommodates -

```{r}

# summary(df_x$availability_30)
# summary(df_x$availability_60)
# summary(df_x$availability_90)
avail_vars <- df_x %>%
  select(availability_30, availability_60, availability_90, availability_365, accommodates)

processed_vars <- preProcess(avail_vars, method = c("YeoJohnson"))

df_x <- predict(processed_vars, df_x)
  # test data
tdf <- predict(preProcess(tdf %>% select(availability_30, availability_60, availability_90, availability_365, accommodates), method = c("YeoJohnson")), tdf)

```

Let's take a look at cleaning fee and replace NAs with the median

```{r}
qplot(df_x$cleaning_fee)
qplot(df_x$security_deposit)

df_x$cleaning_fee <- replace_na(df_x$cleaning_fee, 50)

summary(df_x$cleaning_fee)
```

Create standardized columns for price, cleaning_fee, security_deposit, maximum_nights

```{r}
processed_vars <- preProcess(df_x %>% select(price, extra_people, maximum_nights), method = "YeoJohnson")
df_x <- predict(processed_vars, df_x)
  # test data
tdf <- predict(preProcess(tdf %>% select(price, extra_people, maximum_nights), method = "YeoJohnson"), tdf)
```

Minimum Nights dummies

```{r}

# summary(df_x$minimum_nights)

# View(table(df_x$minimum_nights))

df_x$minimum_nights[df_x$minimum_nights > 1250] <- 100 # random
# summary(df_x$minimum_nights)

df_x <- df_x %>%
  mutate(
    minNigh1 = ifelse(minimum_nights == 1, 1, 0),
    minNigh2 = ifelse(minimum_nights == 2, 1, 0),
    minNigh3 = ifelse(minimum_nights == 3, 1, 0),
    minNight_Excess = ifelse(minimum_nights > 3, 1, 0)
  )
  # test data
tdf <- tdf %>%
  mutate(
    minNigh1 = ifelse(minimum_nights == 1, 1, 0),
    minNigh2 = ifelse(minimum_nights == 2, 1, 0),
    minNigh3 = ifelse(minimum_nights == 3, 1, 0),
    minNight_Excess = ifelse(minimum_nights > 3, 1, 0)
  )
```

Dummies for presence of cleaning fee and security deposit -

(Commented because combined cleaning_fee with price and created dummies for security_deposit)

```{r}
# df_x <- df_x %>%
#   mutate(
#     isCleaningFee = ifelse(is.na(cleaning_fee) | cleaning_fee == 0, 0, 1),
#     isSecurityDeposit = ifelse(is.na(security_deposit) | security_deposit == 0, 0, 1)
#   )
#   # test data
# tdf <- tdf %>%
#   mutate(
#     isCleaningFee = ifelse(is.na(cleaning_fee) | cleaning_fee == 0, 0, 1),
#     isSecurityDeposit = ifelse(is.na(security_deposit) | security_deposit == 0, 0, 1)
#   )
```

host_response_rate, host_listings_count, host_total_listings_count

```{r}
# qplot(df_x_main$host_listings_count, df_x_main$host_total_listings_count)

# Both are same

df_x$host_response_rate <- replace_na(df_x$host_response_rate, 100)
  # test data
tdf$host_response_rate <- replace_na(tdf$host_response_rate, 100)

# Scale

df_x <- predict(preProcess(df_x %>% select(host_listings_count, host_response_rate), method = c("YeoJohnson")), df_x)
  # test data
tdf <- predict(preProcess(tdf %>% select(host_listings_count, host_response_rate), method = c("YeoJohnson")), tdf)
```

```{r}
fset = c("accommodates",
"availability_30",
"availability_365",
"availability_60",
"availability_90",
"extra_people",
"guests_included",
"host_has_profile_pic",
"host_identity_verified",
"host_is_superhost",
"host_listings_count",
"host_response_rate",
"instant_bookable",
"is_location_exact",
"maximum_nights",
"require_guest_phone_verification",
"require_guest_profile_picture",
"requires_license",
"host_lowExp",
"host_lowMedExp",
"host_medExp",
"host_medHighExp",
"host_highExp",
"NoGap_sTor",
"Yr1Gap_sTor",
"HighGap_sTor",
"In_NAS",
"In_LA",
"In_SD",
"In_WDC",
"In_NWO",
"In_SFO",
"In_NYC",
"In_SEA",
"In_CHI",
"In_BOS",
"In_AUS",
"In_PO",
"In_DEN",
"In_SCU",
"In_OAK",
"In_ASH",
"CancelPol_Strict",
"CancelPol_Mod",
"CancelPol_Flexy",
"WholePlace",
"PrivateRoom",
"SharedRoom",
"propertyApartment",
"propertyHouse",
"propertyHotel",
"propertyHoliday",
"propertyOther",
"bed_Real",
"bed_Uncomfy",
"hRes_FewDays",
"hRes_1Day",
"hRes_FewHours",
"hRes_1Hour",
"verifs_vLow",
"verifs_Med",
"verifs_High",
"verifs_VHigh",
"facebookVer",
"googleVer",
"govtIDVer",
"jumioVer",
"kbaVer",
"vlowAmens",
"lowAmens",
"medAmens",
"highAmens",
"vhighAmens",
"hasKitchen1",
"hasKitchen2",
"hasHeating",
"hasAC",
"hasTV",
"hasWiFi",
"PetsAllowed",
"hasLuxuryAmens",
"petsLiveHere",
"hasWorkspace",
"hasFreeParking",
"extraBedding",
"hasElevator",
"hasPrivacyAmens",
"NoSmoking",
"isHost_in_US",
"secDep0",
"secDepGen",
"secDepHigh",
"vlow_pPG",
"low_pPG",
"med_pPG",
"high_pPG",
"vHigh_pPG",
"beds_Comfy",
"beds_Cramped",
"beds_Excess",
"baths_Comfy",
"baths_Cramped",
"baths_Excess",
"bedrooms_Comfy",
"bedrooms_Cramped",
"bedrooms_Excess",
"minNigh1",
"minNigh2",
"minNigh3",
"minNight_Excess")

df <- df_x[, fset]
```

Handle missingness

```{r}
View(colSums(is.na(df)))

# NoGap_sTor	222
df$NoGap_sTor[is.na(df$NoGap_sTor)] <- 1

# Yr1Gap_sTor	222
df$Yr1Gap_sTor[is.na(df$Yr1Gap_sTor)] <- 0

# HighGap_sTor	222
df$HighGap_sTor[is.na(df$HighGap_sTor)] <- 0

# host_listings_count	151
df$host_listings_count[is.na(df$host_listings_count)] <- 2

# host_lowExp	151
df$host_lowExp[is.na(df$host_lowExp)] <- 1

# host_lowMedExp	151
df$host_lowMedExp[is.na(df$host_lowMedExp)] <- 0

# host_medExp	151
df$host_medExp[is.na(df$host_medExp)] <- 0

# host_medHighExp	151
df$host_medHighExp[is.na(df$host_medHighExp)] <- 0

# host_highExp	151
df$host_highExp[is.na(df$host_highExp)] <- 0

# host_identity_verified	148
df$host_identity_verified[is.na(df$host_identity_verified)] <- 1

# host_has_profile_pic	142
df$host_has_profile_pic[is.na(df$host_has_profile_pic)] <- 1

# host_is_superhost	142
df$host_is_superhost[is.na(df$host_is_superhost)] <- 0

# is_location_exact	19
df$is_location_exact[is.na(df$is_location_exact)] <- 0

# maximum_nights	19
df$maximum_nights[is.na(df$maximum_nights)] <- 9.8635

# require_guest_phone_verification	19
df$require_guest_phone_verification[is.na(df$require_guest_phone_verification)] <- 0

# require_guest_profile_picture	19
df$require_guest_profile_picture[is.na(df$require_guest_profile_picture)] <- 0

# requires_license	19
df$requires_license[is.na(df$requires_license)] <- 0

# WholePlace	19
df$WholePlace[is.na(df$WholePlace)] <- 0

# PrivateRoom	19
df$PrivateRoom[is.na(df$PrivateRoom)] <- 1

# SharedRoom	19
df$SharedRoom[is.na(df$SharedRoom)] <- 0

# verifs_vLow	19
df$verifs_vLow[is.na(df$verifs_vLow)] <- 0

# verifs_Med	19
df$verifs_Med[is.na(df$verifs_Med)] <- 1

# verifs_High	19
df$verifs_High[is.na(df$verifs_High)] <- 0

# verifs_VHigh	19
df$verifs_VHigh[is.na(df$verifs_VHigh)] <- 0

# secDep0	19
df$secDep0[is.na(df$secDep0)] <- 1

# secDepGen	19
df$secDepGen[is.na(df$secDepGen)] <- 0

# secDepHigh	19
df$secDepHigh[is.na(df$secDepHigh)] <- 0

# vlow_pPG	19
df$vlow_pPG[is.na(df$vlow_pPG)] <- 0

# low_pPG	19
df$low_pPG[is.na(df$low_pPG)] <- 0

# med_pPG	19
df$med_pPG[is.na(df$med_pPG)] <- 1

# high_pPG	19
df$high_pPG[is.na(df$high_pPG)] <- 0


# vHigh_pPG	19
df$vHigh_pPG[is.na(df$vHigh_pPG)] <- 0

# minNigh1	19
df$minNigh1[is.na(df$minNigh1)] <- 1

# minNigh2	19
df$minNigh2[is.na(df$minNigh2)] <- 0

# minNigh3	19
df$minNigh3[is.na(df$minNigh3)] <- 0

# minNight_Excess
df$minNight_Excess[is.na(df$minNight_Excess)] <- 0

# df_y.high_booking_rate	19
# df$df_y.high_booking_rate[is.na(df$df_y.high_booking_rate)] <- 0

# instant_bookable	12
df$instant_bookable[is.na(df$instant_bookable)] <- 1

# accommodates	9
df$accommodates[is.na(df$accommodates)] <- 50

# availability_30	9
df$availability_30[is.na(df$availability_30)] <- 3.5

# availability_365	9
df$availability_365[is.na(df$availability_365)] <- 16

# availability_60	9
df$availability_60[is.na(df$availability_60)] <- 6.5

# availability_90	9
df$availability_90[is.na(df$availability_90)] <- 10.7

# extra_people	9
df$extra_people[is.na(df$extra_people)] <- 2

# In_NAS	9
df$In_NAS[is.na(df$In_NAS)] <- 0

# In_LA	9
df$In_LA[is.na(df$In_LA)] <- 0

# In_SD	9
df$In_SD[is.na(df$In_SD)] <- 0

# In_WDC	9
df$In_WDC[is.na(df$In_WDC)] <- 1

# In_NWO	9
df$In_NWO[is.na(df$In_NWO)] <- 0

# In_SFO	9
df$In_SFO[is.na(df$In_SFO)] <- 0

# In_NYC	9
df$In_NYC[is.na(df$In_NYC)] <- 0

# In_SEA	9
df$In_SEA[is.na(df$In_SEA)] <- 0

# In_CHI	9
df$In_CHI[is.na(df$In_CHI)] <- 0

# In_BOS	9
df$In_BOS[is.na(df$In_BOS)] <- 0

# In_AUS	9
df$In_AUS[is.na(df$In_AUS)] <- 0

# In_PO	9
df$In_PO[is.na(df$In_PO)] <- 0

# In_DEN	9
df$In_DEN[is.na(df$In_DEN)] <- 0

# In_SCU	9
df$In_SCU[is.na(df$In_SCU)] <- 0

# In_OAK	9
df$In_OAK[is.na(df$In_OAK)] <- 0

# In_ASH	9
df$In_ASH[is.na(df$In_ASH)] <- 0

# CancelPol_Mod	9
df$CancelPol_Mod[is.na(df$CancelPol_Mod)] <- 1

# CancelPol_Flexy	9
df$CancelPol_Flexy[is.na(df$CancelPol_Flexy)] <- 0

# bed_Real	9
df$bed_Real[is.na(df$bed_Real)] <- 1

# vlowAmens	9
df$vlowAmens[is.na(df$vlowAmens)] <- 0

# lowAmens	9
df$lowAmens[is.na(df$lowAmens)] <- 0

# medAmens	9
df$medAmens[is.na(df$medAmens)] <- 1

# highAmens	9
df$highAmens[is.na(df$highAmens)] <- 0

# vhighAmens	9
df$vhighAmens[is.na(df$vhighAmens)] <- 0


```


```{r}
View(colSums(is.na(df)))
```

Treaet missingness in the validation set 

```{r}

td <- tdf[,fset]

# hRes_FewDays	1983
# hRes_1Day	1983
# hRes_FewHours	1983

td$hRes_FewHours[is.na(td$hRes_FewHours)] <- 1

# hRes_1Hour	1983


# NoGap_sTor	29
# Yr1Gap_sTor	29
# HighGap_sTor	29

td$NoGap_sTor[is.na(td$NoGap_sTor)] <- 1

# host_identity_verified	23

td$host_identity_verified[is.na(td$host_identity_verified)] <- 1

# host_listings_count	23

td$host_listings_count[is.na(td$host_listings_count)] <- 2

# host_lowExp	23
# host_lowMedExp	23
# host_medExp	23
# host_medHighExp	23
# host_highExp	23

td$host_medExp[is.na(td$host_medExp)] <- 1

# host_has_profile_pic	21
td$host_has_profile_pic[is.na(td$host_has_profile_pic)] <- 1


# host_is_superhost	21
td$host_is_superhost[is.na(td$host_is_superhost)] <- 0

# is_location_exact	3
td$is_location_exact[is.na(td$is_location_exact)] <- 1

# maximum_nights	3
td$maximum_nights[is.na(td$maximum_nights)] <- 9.8


# require_guest_phone_verification	3
td$require_guest_phone_verification[is.na(td$require_guest_phone_verification)] <- 0

# require_guest_profile_picture	3
td$require_guest_profile_picture[is.na(td$require_guest_profile_picture)] <- 0

# requires_license	3
td$requires_license[is.na(td$requires_license)] <- 0

# WholePlace	3
# PrivateRoom	3
# SharedRoom	3
td$PrivateRoom[is.na(td$PrivateRoom)] <- 1

# verifs_vLow	3
# verifs_Med	3
# verifs_High	3
# verifs_VHigh	3
td$verifs_Med[is.na(td$verifs_Med)] <- 1

# secDep0	3
# secDepGen	3
# secDepHigh	3
td$secDepGen[is.na(td$secDepGen)] <- 1

# vlow_pPG	3
# low_pPG	3
# med_pPG	3
# high_pPG	3
# vHigh_pPG	3
td$vlow_pPG[is.na(td$vlow_pPG)] <- 1
# minNigh1	3
# minNigh2	3
# minNigh3	3
# minNight_Excess	3
td$minNigh2[is.na(td$minNigh2)] <- 1
# accommodates	2
td$accommodates[is.na(td$accommodates)] <- 1
# availability_30	2
td$availability_30[is.na(td$availability_30)] <- 3
# availability_365	2
td$availability_365[is.na(td$availability_365)] <- 16
# availability_60	2
td$availability_60[is.na(td$availability_60)] <- 6
# availability_90	2
td$availability_90[is.na(td$availability_90)] <- 1
# extra_people	2
td$extra_people[is.na(td$extra_people)] <- 3
# instant_bookable	2
td$instant_bookable[is.na(td$instant_bookable)] <- 1
# In_NAS	2
# In_LA	2
# In_SD	2
# In_WDC	2
# In_NWO	2
# In_SFO	2
# In_NYC	2
# In_SEA	2
# In_CHI	2
# In_BOS	2
# In_AUS	2
# In_PO	2
# In_DEN	2
# In_SCU	2
# In_OAK	2
# In_ASH	2
td$In_LA[is.na(td$In_LA)] <- 1
# CancelPol_Mod	2
# CancelPol_Flexy	2
td$CancelPol_Flexy[is.na(td$CancelPol_Flexy)] <- 1
# bed_Real	2
td$bed_Real[is.na(td$bed_Real)] <- 1
# vlowAmens	2
td$medAmens[is.na(td$medAmens)] <- 1
# lowAmens	2
# medAmens	2
# highAmens	2
# vhighAmens	2

td <- td %>% replace(is.na(.), 0)
View(colSums(is.na(td)))
```

First, the simplest model - Logistic Regression

```{r}

library(glmnet)
library(caTools)

df_y$high_booking_rate <- replace_na(df_y$high_booking_rate, 0)

dfs <- scale(df)

dfs <- data.frame(dfs, df_y$high_booking_rate)

set.seed(71923)

##select random instances from the total data, and hold out 30% as validation data
train_insts = sample(nrow(dfs), .7*nrow(dfs))
train1 <- dfs[train_insts,]
test1 <- dfs[-train_insts,]

logMod <- glm(df_y.high_booking_rate~., data = train1, family = "binomial")

actuals <- test1$df_y.high_booking_rate

# Predict test
cutoff=0.5
trainTestPreds <- predict(logMod, newdata = test1[,-111], type = 'response')
trainTestClass <- ifelse(trainTestPreds>=cutoff, 1, 0)
table(actuals, trainTestClass)



# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(df_y.high_booking_rate~., data = train1, method="lvq", preProcess="scale", trControl=control)
# estimate variable importance


# For c = 0.4 # 79.43%
# log_test_class
# actuals     0     1
#       0 19279  3140
#       1  3036  4545

# For c = 0.5 # 80.1%
# log_test_class
# actuals     0     1
#       0 20534  1885
#       1  4069  3512

# For c = 0.45 # 79.9%
#  log_test_class
# actuals     0     1
#       0 19961  2458
#       1  3580  4001

# For c = 5.5 # 80.06%
#  log_test_class
# actuals     0     1
#       0 21027  1392
#       1  4589  2992

# dfr <- scale(df)

#ridgeMod <- glmnet(dfr, df_y$high_booking_rate, family = "binomial", alpha = 1, lambda = NULL)

#ridgeTrain <- glmnet(train1[,fset], train1$df_y.high_booking_rate, family = "binomial", alpha = 1, lambda = NULL)

```

```{r}
colSums(is.na(tdf[,fset]))

```

Applying Logistic Model for predicting test data 

```{r}

library(glmnet)
library(caTools)

df_y$high_booking_rate <- replace_na(df_y$high_booking_rate, 0)

dfs1 <- scale(df)
td1 <- scale(td)
td1 <- as.data.frame(td1)

dfs1 <- data.frame(dfs1, df_y$high_booking_rate)


logModFull <- glm(as.factor(df_y.high_booking_rate)~., data = dfs1, family = "binomial")

# actuals <- test1$df_y.high_booking_rate

# Predict test
cutoff=0.5
test_preds <- predict(logModFull, newdata = td1, type = 'response')
log_test_classfn <- ifelse(test_preds>=cutoff, 1, 0)
table(log_test_classfn)

# log_test_classfn
#     0     1 
# 10074  2134 


```

Ridge for validation

```{r}

train1.m <- as.matrix(train1)

cv_train_std <- cv.glmnet(train1.m, factor(train1$df_y.high_booking_rate), type.measure="class", nfolds=10, family="binomial")

lambda <- cv_train_std$lambda.min

std_ridge_logit <- glmnet(train1.m, factor(train1$df_y.high_booking_rate), family="binomial", alpha=0)

cvglm_preds <- predict(std_ridge_logit, as.matrix(test1[,-111]), type="class", s=lambda)

```






XGBoost

```{r}
library(xgboost)

df_y$high_booking_rate <- replace_na(df_y$high_booking_rate, 0)

set.seed(12345)

df_xg <- data.frame(df, df_y$high_booking_rate)
##select random instances from the total data, and hold out 30% as validation data
train_insts = sample(nrow(df_xg), .7*nrow(df_xg))
xg_train <- df_xg[train_insts,]
xg_test <- df_xg[-train_insts,]

xg_classifier = xgboost(data = as.matrix(xg_train[,-111]), label = xg_train$df_y.high_booking_rate, nrounds = 210)

xgtt_pred = predict(xg_classifier, newdata = as.matrix(xg_test[,-111]))
xgtt_pred = (xgtt_pred >= 0.5)*1

table(xg_test$df_y.high_booking_rate, xgtt_pred)

# xgtt_pred #nrounds = 220; 83.04667%
#         0     1
#   0 20587  1921
#   1  3165  4327

# xgtt_pred #nrounds = 210; 83.09%
#         0     1
#   0 20592  1916
#   1  3156  4336


```

Cross Validation (XGBoost)

```{r}

library(caret)

params = list(eta = 0.1, subsample = 0.75, max_depth = 8, gamma = 0.1, min_child_width = 1)

folds = createFolds(df_xg$df_y.high_booking_rate, k = 15)
cv = lapply(folds, function(x) {
  training_fold = df_xg[-x, ]
  test_fold = df_xg[x, ]
  classifier = xgboost(data = as.matrix(training_fold[,-111]), label = training_fold$df_y.high_booking_rate, nrounds = 210, params = params)
  y_pred = predict(classifier, newdata = as.matrix(test_fold[,-111]))
  y_pred = (y_pred >= 0.5)
  cm = table(test_fold[, 111], y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  return(accuracy)
})
accuracy = mean(as.numeric(cv))
accuracy

# Train split; nrounds = 100; k = 10; Avg Acc =  82.86%
# Train split; nrounds = 100; k = 30; Avg Acc = 83.03% 
# Full training set; nrounds = 100; k = 10; Avg Acc = 83.01%
# Full training set; nrounds = 210; k = 30; Avg Acc = 83.19%/83.267%
# Full training set; nrounds = 200; k = 15; Avg Acc = 83.22399
# Full training set; nrounds = 220; k = 15; Avg acc = 83.15901
# Full training set; nrounds = 210; k = 15; With tuned params; Avg acc = 81.9
# Full training set; nrounds = 210; k = 15; With tuned params; Avg acc = 82.5
# Full training set; nrounds = 210; k = 15; eta = 0.1, subsample = 0.75, max_depth = 6, gamma = 0.1, min_child_width = 10; Avg Acc = 83.2%
# Full training set; nrounds = 210; k = 15; eta = 0.1, subsample = 0.75, max_depth = 8, gamma = 0.1, min_child_width = 10; Avg Acc = 83.365%
# Full training set; nrounds = 210; k = 15; eta = 0.1; subsample = 0.75; max_depth = 8; gamma = 0.1; min_child_width = 1; Avg acc = 83.453%
# Full training set; nrounds = 210; k = 15; eta = 0.1; subsample = 0.75; max_depth = 6; gamma = 0.1; min_child_width = 1; Avg acc = 83.175%

# eta = 0.1, subsample = 0.75, max_depth = 8, gamma = 0.1, min_child_width = 1; AVG ACCURACY: 


```


XGBoost Tuned

```{r}
install.packages('xgboost')
library(xgboost)
xgdf = data.frame(df, df_y$high_booking_rate)

# eta = 0.1; subsample = 0.75; max_depth = 8; gamma = 0.1; min_child_width = 1
# params = list(eta = 0.1, subsample = 0.75, max_depth = 6, gamma = 0.1, min_child_width = 1)

params = list(eta = 0.1, subsample = 0.75, max_depth = 8, gamma = 0.1, min_child_width = 1)

xg_classifier = xgboost(data = as.matrix(xgdf[,-111]), label = xgdf$df_y.high_booking_rate, nrounds = 210, params = params)

xg_pred = predict(xg_classifier, newdata = as.matrix(tdf[,fset]))
xg_pred = (xg_pred >= 0.5)

table(xg_pred)

xg_pred = xg_pred*1
```

RandomForest

```{r}
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
set.seed(123)
df_y$high_booking_rate <- as.factor(df_y$high_booking_rate)

rfdf = data.frame(df, df_y$high_booking_rate)

train_insts = sample(nrow(rfdf), .7*nrow(rfdf))
rf_train <- rfdf[train_insts,]
rf_test <- rfdf[-train_insts,]


rf_classifier = randomForest(x = rf_train[,-111],
                          y = rf_train$df_y.high_booking_rate,
                          ntree = 200)
model <- train(df_y.high_booking_rate~., )

# Predicting the Test set results
rf_pred = predict(rf_classifier, newdata = rf_test[,-111])

# Table
table(rf_pred, rf_test$df_y.high_booking_rate) # 82.4%

```

Naive Bayes

```{r}
library(e1071)
nb_classifier = naiveBayes(as.factor(df_y.high_booking_rate) ~ ., data = train1)

# Predicting the Test set results
nb_pred = predict(nb_classifier, newdata = test1[,-111])

table(actuals, nb_pred)
#        nb_pred # 68.1%
# actuals     0     1
#       0 14429  7990
#       1  1572  6009
```

XGBoost (The very first try)

```{r}
install.packages('xgboost')
library(xgboost)
xgdf = data.frame(df, df_y$high_booking_rate)

xg_classifier = xgboost(data = as.matrix(xgdf[,-111]), label = xgdf$df_y.high_booking_rate, nrounds = 210)

xg_class = xgboost(max)

xg_pred = predict(xg_classifier, newdata = as.matrix(tdf[,fset]))
xg_pred = (xg_pred >= 0.5)

table(xg_pred)
```

XGBoost Train Test Split

```{r}

set.seed(12345)

df_xg <- data.frame(df, df_y$high_booking_rate)
##select random instances from the total data, and hold out 30% as validation data
train_insts = sample(nrow(df_xg), .7*nrow(df_xg))
xg_train <- df_xg[train_insts,]
xg_test <- df_xg[-train_insts,]

xg_classifier = xgboost(data = as.matrix(xg_train[,-111]), label = xg_train$df_y.high_booking_rate, nrounds = 220)

xgtt_pred = predict(xg_classifier, newdata = as.matrix(xg_test[,-111]))
xgtt_pred = (xgtt_pred >= 0.5)*1

table(xg_test$df_y.high_booking_rate, xgtt_pred)
# xgtt_pred # 81.09% nrounds = 10
#         0     1
#   0 20923  1486
#   1  4185  3406

# xgtt_pred #83.00333%  nrounds = 100
#         0     1
#   0 20720  1689
#   1  3410  4181

 # xgtt_pred # 82.848 nrounds = 500 
 #        0     1
 #  0 17117  1576
 #  1  2712  3595

# xgtt_pred # 82.52
#         0     1
#   0 16978  1830
#   1  2540  3652

#  xgtt_pred # 83.06667 nrounds = 150
#       0     1
# 0 20636  1872
# 1  3208  4284


# xgtt_pred # 83.0833 nrounds = 200
#         0     1
#   0 20587  1921
#   1  3154  4338

 # xgtt_pred # 82.9 nrounds = 300
 #        0     1
 #  0 20532  1976
 #  1  3150  4342

# xgtt_pred # 82.91 nrounds = 250
#         0     1
#   0 20553  1955
#   1  3172  4320

# xgtt_pred # 82.98 nrounds = 240
#         0     1
#   0 20567  1941
#   1  3164  4328

# xgtt_pred # 83.0133 nrounds = 230
#         0     1
#   0 20572  1936
#   1  3160  4332

# xgtt_pred # 83.04667 nrounds = 220
#         0     1
#   0 20587  1921
#   1  3165  4327

# xgtt_pred # 83.09 nrounds = 210
#         0     1
#   0 20592  1916
#   1  3156  4336

length(xgtt_pred)

length(xg_test$df_y.high_booking_rate)

```

Cross Validation -

```{r}
library(caret)

params = list(eta = 0.05, subsample = 0.75, max_depth = 4, gamma = 0.1, min_child_width = 10)

folds = createFolds(df_xg$df_y.high_booking_rate, k = 15)
cv = lapply(folds, function(x) {
  training_fold = df_xg[-x, ]
  test_fold = df_xg[x, ]
  classifier = xgboost(data = as.matrix(training_fold[,-111]), label = training_fold$df_y.high_booking_rate, nrounds = 210, pparams = params)
  y_pred = predict(classifier, newdata = as.matrix(test_fold[,-111]))
  y_pred = (y_pred >= 0.5)
  cm = table(test_fold[, 111], y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  return(accuracy)
})
accuracy = mean(as.numeric(cv))
accuracy

# Train split; nrounds = 100; k = 10; Avg Acc =  82.86%
# Train split; nrounds = 100; k = 30; Avg Acc = 83.03% 
# Full training set; nrounds = 100; k = 10; Avg Acc = 83.01%
# Full training set; nrounds = 210; k = 30; Avg Acc = 83.19%/83.267%
# Full training set; nrounds = 200; k = 15; Avg Acc = 83.22399
# Full training set; nrounds = 220; k = 15; Avg acc = 83.15901
# Full training set; nrounds = 210; k = 15; With tuned params; Avg acc = 
```

Using nbounds = 210 for data with fset

```{r}

xgdf = data.frame(df, df_y$high_booking_rate)

xg_classifier = xgboost(data = as.matrix(xgdf[,-111]), label = xgdf$df_y.high_booking_rate, nrounds = 210)

xg_pred = predict(xg_classifier, newdata = as.matrix(tdf[,fset]))
xg_pred = (xg_pred >= 0.5)*1

```

Predict with test set

```{r}

xg_classifier = xgboost(data = as.matrix(xgdf[,-111]), label = xgdf$df_y.high_booking_rate, nrounds = 10)

xg1_pred = predict(xg_classifier, newdata = as.matrix(tdf[,fset]))
xg1_pred = (xg1_pred >= 0.5)*1

```


Feature Set 2 

```{r}
fset2 = c("accommodates",
"availability_30",
"availability_365",
"availability_60",
"availability_90",
"bathrooms",
"bedrooms",
"beds",
"extra_people",
"guests_included",
"host_has_profile_pic",
"host_identity_verified",
"host_is_superhost",
"host_listings_count",
"host_response_rate",
"instant_bookable",
"is_location_exact",
"maximum_nights",
"minimum_nights",
"price",
"require_guest_phone_verification",
"require_guest_profile_picture",
"requires_license",
"host_lowExp",
"host_lowMedExp",
"host_medExp",
"host_medHighExp",
"host_highExp",
"NoGap_sTor",
"Yr1Gap_sTor",
"HighGap_sTor",
"In_NAS",
"In_LA",
"In_SD",
"In_WDC",
"In_NWO",
"In_SFO",
"In_NYC",
"In_SEA",
"In_CHI",
"In_BOS",
"In_AUS",
"In_PO",
"In_DEN",
"In_SCU",
"In_OAK",
"In_ASH",
"CancelPol_Strict",
"CancelPol_Mod",
"CancelPol_Flexy",
"WholePlace",
"PrivateRoom",
"SharedRoom",
"propertyApartment",
"propertyHouse",
"propertyHotel",
"propertyHoliday",
"propertyOther",
"bed_Real",
"bed_Uncomfy",
"hRes_FewDays",
"hRes_1Day",
"hRes_FewHours",
"hRes_1Hour",
"verifs_vLow",
"verifs_Med",
"verifs_High",
"verifs_VHigh",
"facebookVer",
"googleVer",
"govtIDVer",
"jumioVer",
"kbaVer",
"vlowAmens",
"lowAmens",
"medAmens",
"highAmens",
"vhighAmens",
"hasKitchen1",
"hasKitchen2",
"hasHeating",
"hasAC",
"hasTV",
"hasWiFi",
"PetsAllowed",
"hasLuxuryAmens",
"petsLiveHere",
"hasWorkspace",
"hasFreeParking",
"extraBedding",
"hasElevator",
"hasPrivacyAmens",
"NoSmoking",
"isHost_in_US",
"secDep0",
"secDepGen",
"secDepHigh",
"vlow_pPG",
"low_pPG",
"med_pPG",
"high_pPG",
"vHigh_pPG",
"beds_Comfy",
"beds_Cramped",
"beds_Excess",
"baths_Comfy",
"baths_Cramped",
"baths_Excess",
"bedrooms_Comfy",
"bedrooms_Cramped",
"bedrooms_Excess",
"minNigh1",
"minNigh2",
"minNigh3",
"minNight_Excess")

df2 <- df_x[, fset2]
```

Dealing with missingness, first with the training set

```{r}
# minimum_nights # median 2
df2$minimum_nights[is.na(df2$minimum_nights)] <- 2
# price # median 3.8
df2$price[is.na(df2$price)] <- 3.8
# bathrooms # median 3
df2$bathrooms[is.na(df2$bathrooms)] <- 3
# bedrooms # median 2
df2$bedrooms[is.na(df2$bedrooms)] <- 2
# beds # median 2
df2$beds[is.na(df2$beds)] <- 2

# NoGap_sTor	222
df2$NoGap_sTor[is.na(df2$NoGap_sTor)] <- 1
# Yr1Gap_sTor	222
df2$Yr1Gap_sTor[is.na(df2$Yr1Gap_sTor)] <- 0
# HighGap_sTor	222
df2$HighGap_sTor[is.na(df2$HighGap_sTor)] <- 0
# host_listings_count	151
df2$host_listings_count[is.na(df2$host_listings_count)] <- 2
# host_lowExp	151
df2$host_lowExp[is.na(df2$host_lowExp)] <- 1
# host_lowMedExp	151
df2$host_lowMedExp[is.na(df2$host_lowMedExp)] <- 0
# host_medExp	151
df2$host_medExp[is.na(df2$host_medExp)] <- 0
# host_medHighExp	151
df2$host_medHighExp[is.na(df2$host_medHighExp)] <- 0
# host_highExp	151
df2$host_highExp[is.na(df2$host_highExp)] <- 0
# host_identity_verified	148
df2$host_identity_verified[is.na(df2$host_identity_verified)] <- 1
# host_has_profile_pic	142
df2$host_has_profile_pic[is.na(df2$host_has_profile_pic)] <- 1
# host_is_superhost	142
df2$host_is_superhost[is.na(df2$host_is_superhost)] <- 0
# is_location_exact	19
df2$is_location_exact[is.na(df2$is_location_exact)] <- 0
# maximum_nights	19
df2$maximum_nights[is.na(df2$maximum_nights)] <- 9.8635
# require_guest_phone_verification	19
df2$require_guest_phone_verification[is.na(df2$require_guest_phone_verification)] <- 0
# require_guest_profile_picture	19
df2$require_guest_profile_picture[is.na(df2$require_guest_profile_picture)] <- 0
# requires_license	19
df2$requires_license[is.na(df2$requires_license)] <- 0
# WholePlace	19
df2$WholePlace[is.na(df2$WholePlace)] <- 0
# PrivateRoom	19
df2$PrivateRoom[is.na(df2$PrivateRoom)] <- 1
# SharedRoom	19
df2$SharedRoom[is.na(df2$SharedRoom)] <- 0
# verifs_vLow	19
df2$verifs_vLow[is.na(df2$verifs_vLow)] <- 0
# verifs_Med	19
df2$verifs_Med[is.na(df2$verifs_Med)] <- 1
# verifs_High	19
df2$verifs_High[is.na(df2$verifs_High)] <- 0
# verifs_VHigh	19
df2$verifs_VHigh[is.na(df2$verifs_VHigh)] <- 0
# secDep0	19
df2$secDep0[is.na(df2$secDep0)] <- 1
# secDepGen	19
df2$secDepGen[is.na(df2$secDepGen)] <- 0
# secDepHigh	19
df2$secDepHigh[is.na(df2$secDepHigh)] <- 0
# vlow_pPG	19
df2$vlow_pPG[is.na(df2$vlow_pPG)] <- 0
# low_pPG	19
df2$low_pPG[is.na(df2$low_pPG)] <- 0
# med_pPG	19
df2$med_pPG[is.na(df2$med_pPG)] <- 1
# high_pPG	19
df2$high_pPG[is.na(df2$high_pPG)] <- 0
# vHigh_pPG	19
df2$vHigh_pPG[is.na(df2$vHigh_pPG)] <- 0
# minNigh1	19
df2$minNigh1[is.na(df2$minNigh1)] <- 1
# minNigh2	19
df2$minNigh2[is.na(df2$minNigh2)] <- 0
# minNigh3	19
df2$minNigh3[is.na(df2$minNigh3)] <- 0
#minNight_Excess
df2$minNight_Excess[is.na(df2$minNight_Excess)] <- 0
# instant_bookable	12
df2$instant_bookable[is.na(df2$instant_bookable)] <- 1
# accommodates	9
df2$accommodates[is.na(df2$accommodates)] <- 50
# availability_30	9
df2$availability_30[is.na(df2$availability_30)] <- 3.5
# availability_365	9
df2$availability_365[is.na(df2$availability_365)] <- 16
# availability_60	9
df2$availability_60[is.na(df2$availability_60)] <- 6.5
# availability_90	9
df2$availability_90[is.na(df2$availability_90)] <- 10.7
# extra_people	9
df2$extra_people[is.na(df2$extra_people)] <- 2
# In_NAS	9
df2$In_NAS[is.na(df2$In_NAS)] <- 0
# In_LA	9
df2$In_LA[is.na(df2$In_LA)] <- 0
# In_SD	9
df2$In_SD[is.na(df2$In_SD)] <- 0
# In_WDC	9
df2$In_WDC[is.na(df2$In_WDC)] <- 1
# In_NWO	9
df2$In_NWO[is.na(df2$In_NWO)] <- 0
# In_SFO	9
df2$In_SFO[is.na(df2$In_SFO)] <- 0
# In_NYC	9
df2$In_NYC[is.na(df2$In_NYC)] <- 0
# In_SEA	9
df2$In_SEA[is.na(df2$In_SEA)] <- 0
# In_CHI	9
df2$In_CHI[is.na(df2$In_CHI)] <- 0
# In_BOS	9
df2$In_BOS[is.na(df2$In_BOS)] <- 0
# In_AUS	9
df2$In_AUS[is.na(df2$In_AUS)] <- 0
# In_PO	9
df2$In_PO[is.na(df2$In_PO)] <- 0
# In_DEN	9
df2$In_DEN[is.na(df2$In_DEN)] <- 0
# In_SCU	9
df2$In_SCU[is.na(df2$In_SCU)] <- 0
# In_OAK	9
df2$In_OAK[is.na(df2$In_OAK)] <- 0
# In_ASH	9
df2$In_ASH[is.na(df2$In_ASH)] <- 0
# CancelPol_Mod	9
df2$CancelPol_Mod[is.na(df2$CancelPol_Mod)] <- 1
# CancelPol_Flexy	9
df2$CancelPol_Flexy[is.na(df2$CancelPol_Flexy)] <- 0
# bed_Real	9
df2$bed_Real[is.na(df2$bed_Real)] <- 1
# vlowAmens	9
df2$vlowAmens[is.na(df2$vlowAmens)] <- 0
# lowAmens	9
df2$lowAmens[is.na(df2$lowAmens)] <- 0
# medAmens	9
df2$medAmens[is.na(df2$medAmens)] <- 1
# highAmens	9
df2$highAmens[is.na(df2$highAmens)] <- 0
# vhighAmens	9
df2$vhighAmens[is.na(df2$vhighAmens)] <- 0

```

Dealing with missingness - test set

```{r}

td2 <- tdf[,fset2]

# minimum_nights # median 2
td2$minimum_nights[is.na(td2$minimum_nights)] <- 2
# price # median 3.8
td2$price[is.na(td2$price)] <- 3.8
# bathrooms # median 3
td2$bathrooms[is.na(td2$bathrooms)] <- 3
# bedrooms # median 2
td2$bedrooms[is.na(td2$bedrooms)] <- 2
# beds # median 2
td2$beds[is.na(td2$beds)] <- 2

# hRes_FewDays	1983
# hRes_1Day	1983
# hRes_FewHours	1983
# hRes_1Hour	1983
td2$hRes_FewHours[is.na(td2$hRes_FewHours)] <- 1

# NoGap_sTor	29
# Yr1Gap_sTor	29
# HighGap_sTor	29
td2$NoGap_sTor[is.na(td2$NoGap_sTor)] <- 1

# host_identity_verified	23
td2$host_identity_verified[is.na(td2$host_identity_verified)] <- 1

# host_listings_count	23
td2$host_listings_count[is.na(td2$host_listings_count)] <- 2

# host_lowExp	23
# host_lowMedExp	23
# host_medExp	23
# host_medHighExp	23
# host_highExp	23
td2$host_medExp[is.na(td2$host_medExp)] <- 1

# host_has_profile_pic	21
td2$host_has_profile_pic[is.na(td2$host_has_profile_pic)] <- 1

# host_is_superhost	21
td2$host_is_superhost[is.na(td2$host_is_superhost)] <- 0

# is_location_exact	3
td2$is_location_exact[is.na(td2$is_location_exact)] <- 1

# maximum_nights	3
td2$maximum_nights[is.na(td2$maximum_nights)] <- 9.8

# require_guest_phone_verification	3
td2$require_guest_phone_verification[is.na(td2$require_guest_phone_verification)] <- 0

# require_guest_profile_picture	3
td2$require_guest_profile_picture[is.na(td2$require_guest_profile_picture)] <- 0

# requires_license	3
td2$requires_license[is.na(td2$requires_license)] <- 0

# WholePlace	3
# PrivateRoom	3
# SharedRoom	3
td2$PrivateRoom[is.na(td2$PrivateRoom)] <- 1

# verifs_vLow	3
# verifs_Med	3
# verifs_High	3
# verifs_VHigh	3
td2$verifs_Med[is.na(td2$verifs_Med)] <- 1

# secDep0	3
# secDepGen	3
# secDepHigh	3
td2$secDepGen[is.na(td2$secDepGen)] <- 1

# vlow_pPG	3
# low_pPG	3
# med_pPG	3
# high_pPG	3
# vHigh_pPG	3
td2$vlow_pPG[is.na(td2$vlow_pPG)] <- 1

# minNigh1	3
# minNigh2	3
# minNigh3	3
# minNight_Excess	3
td2$minNigh2[is.na(td2$minNigh2)] <- 1

# accommodates	2
td2$accommodates[is.na(td2$accommodates)] <- 1

# availability_30	2
td2$availability_30[is.na(td2$availability_30)] <- 3

# availability_365	2
td2$availability_365[is.na(td2$availability_365)] <- 16

# availability_60	2
td2$availability_60[is.na(td2$availability_60)] <- 6

# availability_90	2
td2$availability_90[is.na(td2$availability_90)] <- 1

# extra_people	2
td2$extra_people[is.na(td2$extra_people)] <- 3

# instant_bookable	2
td2$instant_bookable[is.na(td2$instant_bookable)] <- 1

# In_NAS	2
# In_LA	2
# In_SD	2
# In_WDC	2
# In_NWO	2
# In_SFO	2
# In_NYC	2
# In_SEA	2
# In_CHI	2
# In_BOS	2
# In_AUS	2
# In_PO	2
# In_DEN	2
# In_SCU	2
# In_OAK	2
# In_ASH	2
td2$In_LA[is.na(td2$In_LA)] <- 1

# CancelPol_Mod	2
# CancelPol_Flexy	2
td2$CancelPol_Flexy[is.na(td2$CancelPol_Flexy)] <- 1

# bed_Real	2
td2$bed_Real[is.na(td2$bed_Real)] <- 1

# vlowAmens	2
# lowAmens	2
# medAmens	2
# highAmens	2
# vhighAmens	2
td2$medAmens[is.na(td2$medAmens)] <- 1

td2 <- td2 %>% replace(is.na(.), 0)
View(colSums(is.na(td2)))


```

Time for XGBoost.

```{r}

set.seed(123)

df2_xg <- data.frame(df2, df_y$high_booking_rate)
##select random instances from the total data, and hold out 30% as validation data
train_insts = sample(nrow(df2_xg), .7*nrow(df2_xg))
xg2_train <- df2_xg[train_insts,]
xg2_test <- df2_xg[-train_insts,]

xg2_classifier = xgboost(data = as.matrix(xg2_train[,-116]), label = xg2_train$df_y.high_booking_rate, nrounds = 200)

xgtt2_pred = predict(xg2_classifier, newdata = as.matrix(xg2_test[,-116]))
xgtt2_pred = (xgtt2_pred >= 0.5)*1

table(xg2_test$df_y.high_booking_rate, xgtt2_pred)

# nrounds = 100; 83.02667%
# xgtt2_pred
#        0     1
#  0 20687  1722
#  1  3370  4221

# nrounds = 300; 82.9%
# xgtt2_pred
#         0     1
#   0 20572  1837
#   1  3293  4298

# nrounds = 210; 83.033%
# xgtt2_pred
#         0     1
#   0 20629  1780

# nrounds = 220; 83.02667%
# xgtt2_pred
#         0     1
#   0 20620  1789
#   1  3303  4288

# nrounds = 230; 82.9%
# xgtt2_pred
#         0     1
#   0 20599  1810
#   1  3312  4279


# nrounds = 200; 82.989%
# xgtt2_pred
#         0     1
#   0 20636  1773
#   1  3322  4269

```

Cross-Fold Validation

```{r}

library(caret)

folds = createFolds(df2_xg$df_y.high_booking_rate, k = 10)
cv = lapply(folds, function(x) {
  training_fold = df2_xg[-x, ]
  test_fold = df2_xg[x, ]
  classifier = xgboost(data = as.matrix(training_fold[,-116]), label = training_fold$df_y.high_booking_rate, nrounds = 150)
  y_pred = predict(classifier, newdata = as.matrix(test_fold[,-116]))
  y_pred = (y_pred >= 0.5)
  cm = table(test_fold[, 111], y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  return(accuracy)
})
accuracy = mean(as.numeric(cv))
accuracy

# k = 10; nrounds = 210; accuracy = 70.681%
# k = 10; nrounds = 100; accuracy = 71.008%
# k = 10; nrounds = 150; accuracy = 70.664%

```

XGBoost with tuning

```{r}
k <- read.csv("airbnb_train_y.csv")

set.seed(12345)

dft_xg <- data.frame(df, df_y$high_booking_rate)
dft_xg$df_y.high_booking_rate <- as.factor(dft_xg$df_y.high_booking_rate)
##select random instances from the total data, and hold out 30% as validation data
train_insts = sample(nrow(dft_xg), .7*nrow(dft_xg))
xgt_train <- dft_xg[train_insts,]
xgt_test <- dft_xg[-train_insts,]

#xg_classifier = xgboost(data = as.matrix(xgt_train[,-111]), label = xgt_train$df_y.high_booking_rate, nrounds = 220)

#xgtt_pred = predict(xg_classifier, newdata = as.matrix(xg_test[,-111]))
#xgtt_pred = (xgtt_pred >= 0.5)*1

#table(xg_test$df_y.high_booking_rate, xgtt_pred)


# = parameters = #
# = eta candidates = #
eta=c(0.05,0.1,0.2,0.5,1)
# = colsample_bylevel candidates = #
cs=c(1/3,2/3,1)
# = max_depth candidates = #
md=c(2,4,6,10)
# = sub_sample candidates = #
ss=c(0.25,0.5,0.75,1)
 
# = standard model is the second value  of each vector above = #
standard=c(2,2,3,2)

library(xgboost)

set.seed(1)
conv_eta = matrix(NA,500,length(eta))
pred_eta = matrix(NA,length(xgt_test$df_y.high_booking_rate), length(eta))
colnames(conv_eta) = colnames(pred_eta) = eta
for(i in 1:length(eta)){
  params=list(eta = eta[i], colsample_bylevel=cs[standard[2]],
              subsample = ss[standard[4]], max_depth = md[standard[3]],
              min_child_weigth = 1)
  xgb=xgboost(as.matrix(xgt_train[,-111]), label = xgt_train$df_y.high_booking_rate, nrounds = 500, params = params)
  conv_eta[,i] = xgb$evaluation_log$train_rmse
  pred_eta[,i] = predict(xgb, as.matrix(xgt_test[,-111]))
}


conv_eta = data.frame(iter=1:500, conv_eta)
conv_eta = melt(conv_eta, id.vars = "iter")
ggplot(data = conv_eta) + geom_line(aes(x = iter, y = value, color = variable))

(RMSE_eta = sqrt(colMeans((as.numeric(xgt_test$df_y.high_booking_rate)-pred_eta)^2)))

# eta  0.05       0.1       0.2       0.5         1 
# rmse 0.3425354 0.3456618 0.3552726 0.4141428 0.6516247 

# Let's go with o.05

```

Tune the colsample_bylevel

```{r}
set.seed(1)
conv_cs = matrix(NA,500,length(cs))
pred_cs = matrix(NA,length(xgt_test$df_y.high_booking_rate), length(cs))
colnames(conv_cs) = colnames(pred_cs) = cs
for(i in 1:length(cs)){
  params = list(eta = eta[standard[1]], colsample_bylevel = cs[i],
              subsample = ss[standard[4]], max_depth = md[standard[3]],
              min_child_weigth = 1)
  xgb=xgboost(as.matrix(xgt_train[,-111]), label = xgt_train$df_y.high_booking_rate, nrounds = 500, params = params)
  conv_cs[,i] = xgb$evaluation_log$train_rmse
  pred_cs[,i] = predict(xgb, as.matrix(xgt_test[,-111]))
}

conv_cs = data.frame(iter=1:500, conv_cs)
conv_cs = melt(conv_cs, id.vars = "iter")
ggplot(data = conv_cs) + geom_line(aes(x = iter, y = value, color = variable))

(RMSE_cs = sqrt(colMeans((as.numeric(xgt_test$df_y.high_booking_rate)-pred_cs)^2)))
# 0.333333333333333 0.666666666666667                 1 
#         0.3448943         0.3456618         0.3448457 

```

max_depth

```{r}

set.seed(1)
conv_md=matrix(NA,500,length(md))
pred_md=matrix(NA,length(xgt_test$df_y.high_booking_rate), length(md))
colnames(conv_md)=colnames(pred_md)=md
for(i in 1:length(md)){
  params=list(eta=eta[standard[1]],colsample_bylevel=cs[standard[2]],
              subsample=ss[standard[4]],max_depth=md[i],
              min_child_weigth=1)
  xgb=xgboost(as.matrix(xgt_train[,-111]), label = xgt_train$df_y.high_booking_rate, nrounds = 500, params = params)
  conv_md[,i] = xgb$evaluation_log$train_rmse
  pred_md[,i] = predict(xgb, as.matrix(xgt_test[,-111]))
}

conv_md=data.frame(iter=1:500,conv_md)
conv_md=melt(conv_md,id.vars = "iter")
ggplot(data=conv_md)+geom_line(aes(x=iter,y=value,color=variable))

(RMSE_md=sqrt(colMeans((as.numeric(xgt_test$df_y.high_booking_rate)-pred_md)^2)))

#         2         4         6        10 
# 0.3541707 0.3445640 0.3449211 0.3545224 

```

sub_sample

```{r}

set.seed(1)
conv_ss=matrix(NA,500,length(ss))
pred_ss=matrix(NA,length(xgt_test$df_y.high_booking_rate),length(ss))
colnames(conv_ss)=colnames(pred_ss)=ss
for(i in 1:length(ss)){
  params=list(eta=eta[standard[1]],colsample_bylevel=cs[standard[2]],
              subsample=ss[i],max_depth=md[standard[3]],
              min_child_weigth=1)
  xgb=xgboost(as.matrix(xgt_train[,-111]), label = xgt_train$df_y.high_booking_rate, nrounds = 500, params = params)
  conv_ss[,i] = xgb$evaluation_log$train_rmse
  pred_ss[,i] = predict(xgb, as.matrix(xgt_test[,-111]))
}

conv_ss=data.frame(iter=1:500,conv_ss)
conv_ss=melt(conv_ss,id.vars = "iter")
ggplot(data=conv_ss)+geom_line(aes(x=iter,y=value,color=variable))

(RMSE_ss=sqrt(colMeans((as.numeric(xgt_test$df_y.high_booking_rate)-pred_ss)^2)))

#      0.25       0.5      0.75         1 
# 0.3503900 0.3456618 0.3430353 0.3427949 

# Smaller values result in bigger errors in-sample but it may generate more robust out-of-sample estimates

```

min_child_weight

```{r}

# = min_child_weights candidates = #
mcw=c(1,10,100,400)
# = gamma candidates = #
gamma=c(0.1,1,10,100)



set.seed(1)
conv_mcw = matrix(NA,500,length(mcw))
pred_mcw = matrix(NA,length(xgt_test$df_y.high_booking_rate), length(mcw))
colnames(conv_mcw) = colnames(pred_mcw) = mcw
for(i in 1:length(mcw)){
  params = list(eta = 0.1, colsample_bylevel=2/3,
              subsample = 1, max_depth = 6,
              min_child_weight = mcw[i], gamma = 0)
  xgb = xgboost(as.matrix(xgt_train[,-111]), label = xgt_train$df_y.high_booking_rate, nrounds = 500, params = params)
  conv_mcw[,i] = xgb$evaluation_log$train_rmse
  pred_mcw[,i] = predict(xgb, as.matrix(xgt_test[,-111]))
}
 
conv_mcw = data.frame(iter=1:500, conv_mcw)
conv_mcw = melt(conv_mcw, id.vars = "iter")
ggplot(data = conv_mcw) + geom_line(aes(x = iter, y = value, color = variable))

(RMSE_mcw = sqrt(colMeans((as.numeric(xgt_test$df_y.high_booking_rate)-pred_mcw)^2)))

#      1        10       100       400 
# 0.3430975 0.3430080 0.3431284 0.3440230 

```

gamma

```{r}

set.seed(1)
conv_gamma = matrix(NA,500,length(gamma))
pred_gamma = matrix(NA,length(xgt_test$df_y.high_booking_rate), length(gamma))
colnames(conv_gamma) = colnames(pred_gamma) = gamma
for(i in 1:length(gamma)){
  params = list(eta = 0.1, colsample_bylevel=2/3,
              subsample = 1, max_depth = 6, min_child_weight = 1,
              gamma = gamma[i])
  xgb = xgboost(as.matrix(xgt_train[,-111]), label = xgt_train$df_y.high_booking_rate, nrounds = 500, params = params)
  conv_gamma[,i] = xgb$evaluation_log$train_rmse
  pred_gamma[,i] = predict(xgb, as.matrix(xgt_test[,-111]))
}
 
conv_gamma = data.frame(iter=1:500, conv_gamma)
conv_gamma = melt(conv_gamma, id.vars = "iter")
ggplot(data = conv_gamma) + geom_line(aes(x = iter, y = value, color = variable))

(RMSE_gamma = sqrt(colMeans((as.numeric(xgt_test$df_y.high_booking_rate)-pred_gamma)^2)))

#      0.1         1        10       100 
# 0.3426777 0.3432094 0.3585007 0.3805917 

```

lowest rmse parameters:

gamma = 0.1,
min_child_width = 10,
subsample = 0.75,
max_depth = 4,
colsample_bylevel = 1,
eta = 0.05 or 0.1

```{r}

set.seed(123)

df_xg <- data.frame(df, df_y$high_booking_rate)
##select random instances from the total data, and hold out 30% as validation data
train_insts = sample(nrow(df_xg), .7*nrow(df_xg))
xg3_train <- df_xg[train_insts,]
xg3_test <- df_xg[-train_insts,]

params = list(eta = 0.05, subsample = 0.75, max_depth = 4, gamma = 0.1, min_child_width = 10)

xg3_classifier = xgboost(data = as.matrix(xg3_train[,-111]), label = as.factor(xg3_train$df_y.high_booking_rate), nrounds = 210)

xgtt3_pred = predict(xg3_classifier, newdata = as.matrix(xg3_test[,-111]))
xgtt3_pred = (xgtt3_pred >= 0.5)*1

table(xg3_test$df_y.high_booking_rate, xgtt3_pred)

```



